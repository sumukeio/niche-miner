"""
æ·˜å®å…³é”®è¯æŒ–æ˜å·¥å…·
é€šè¿‡ç§å­è¯æœç´¢æ·˜å®ï¼ŒæŠ“å–ç¬¦åˆé”€é‡èŒƒå›´çš„é•¿å°¾å•†å“æ ‡é¢˜ï¼Œæ¸…æ´—åå­˜å…¥æ•°æ®åº“
"""

import os
import sys
import json
import time
import random
import re
from pathlib import Path
from playwright.sync_api import sync_playwright, Page, TimeoutError as PlaywrightTimeoutError
from typing import List, Dict, Optional
import logging
from supabase import create_client, Client
from dotenv import load_dotenv

# è®¾ç½®æ ‡å‡†è¾“å‡ºå’Œé”™è¯¯è¾“å‡ºä¸º UTF-8 ç¼–ç ï¼ˆè§£å†³ Windows ä¹±ç é—®é¢˜ï¼‰
if sys.platform == 'win32':
    try:
        # è®¾ç½®æ ‡å‡†è¾“å‡ºç¼–ç ä¸º UTF-8
        sys.stdout.reconfigure(encoding='utf-8')
        sys.stderr.reconfigure(encoding='utf-8')
    except:
        # å¦‚æœä¸æ”¯æŒ reconfigureï¼Œä½¿ç”¨ç¯å¢ƒå˜é‡
        os.environ['PYTHONIOENCODING'] = 'utf-8'

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# é…ç½®æ—¥å¿—ï¼ˆç¡®ä¿ UTF-8 ç¼–ç ï¼‰
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
    ]
)
# ç¡®ä¿æ—¥å¿—è¾“å‡ºä½¿ç”¨ UTF-8
for handler in logging.root.handlers:
    if isinstance(handler, logging.StreamHandler):
        if hasattr(handler.stream, 'reconfigure'):
            try:
                handler.stream.reconfigure(encoding='utf-8')
            except:
                pass

logger = logging.getLogger(__name__)


class TaobaoMiner:
    """æ·˜å®å…³é”®è¯æŒ–æ˜å™¨"""
    
    # PCç«¯ User-Agent æ± ï¼ˆéšæœºè½®æ¢ï¼Œå¢å¼ºåçˆ¬ï¼‰
    PC_USER_AGENTS = [
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36",
        "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:121.0) Gecko/20100101 Firefox/121.0",
        "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.1 Safari/605.1.15",
    ]
    
    def __init__(self, headless: bool = False, auth_file: str = "auth_taobao.json", 
                 supabase_url: Optional[str] = None, supabase_key: Optional[str] = None):
        """
        åˆå§‹åŒ–æŒ–æ˜å™¨
        
        Args:
            headless: æ˜¯å¦æ— å¤´æ¨¡å¼è¿è¡Œï¼ˆFalse è¡¨ç¤ºæ˜¾ç¤ºæµè§ˆå™¨çª—å£ï¼Œç™»å½•æ—¶å»ºè®® Falseï¼‰
            auth_file: è®¤è¯æ–‡ä»¶è·¯å¾„ï¼ˆä¿å­˜ Cookiesï¼‰
            supabase_url: Supabase é¡¹ç›® URLï¼ˆä»ç¯å¢ƒå˜é‡è¯»å–æˆ–æ‰‹åŠ¨æŒ‡å®šï¼‰
            supabase_key: Supabase API Keyï¼ˆä»ç¯å¢ƒå˜é‡è¯»å–æˆ–æ‰‹åŠ¨æŒ‡å®šï¼‰
        """
        self.headless = headless
        self.auth_file = Path(auth_file)
        self.user_agent = random.choice(self.PC_USER_AGENTS)  # éšæœºé€‰æ‹© User-Agent
        self.viewport = {'width': 1920, 'height': 1080}
        
        # åˆå§‹åŒ– Supabase å®¢æˆ·ç«¯
        self.supabase: Optional[Client] = None
        if supabase_url and supabase_key:
            try:
                self.supabase = create_client(supabase_url, supabase_key)
                logger.info("âœ… Supabase å®¢æˆ·ç«¯å·²åˆå§‹åŒ–")
            except Exception as e:
                logger.warning(f"âš ï¸ Supabase åˆå§‹åŒ–å¤±è´¥: {str(e)}")
        else:
            # å°è¯•ä»ç¯å¢ƒå˜é‡è¯»å–
            supabase_url = os.getenv('SUPABASE_URL') or os.getenv('NEXT_PUBLIC_SUPABASE_URL')
            supabase_key = os.getenv('SUPABASE_KEY') or os.getenv('NEXT_PUBLIC_SUPABASE_ANON_KEY')
            if supabase_url and supabase_key:
                try:
                    self.supabase = create_client(supabase_url, supabase_key)
                    logger.info("âœ… Supabase å®¢æˆ·ç«¯å·²åˆå§‹åŒ–ï¼ˆä»ç¯å¢ƒå˜é‡ï¼‰")
                except Exception as e:
                    logger.warning(f"âš ï¸ Supabase åˆå§‹åŒ–å¤±è´¥: {str(e)}")
            else:
                logger.warning("âš ï¸ æœªé…ç½® Supabaseï¼Œå°†åªæŠ“å–æ•°æ®ä¸å†™å…¥æ•°æ®åº“")
        
        logger.info(f"åˆå§‹åŒ–æ·˜å®æŒ–æ˜å™¨ (User-Agent: {self.user_agent[:50]}...)")
    
    def wait_random(self, min_seconds: float = 2.0, max_seconds: float = 5.0):
        """
        éšæœºç­‰å¾…ï¼Œæ¨¡æ‹ŸçœŸäººæ“ä½œ
        
        Args:
            min_seconds: æœ€å°ç­‰å¾…æ—¶é—´ï¼ˆç§’ï¼‰
            max_seconds: æœ€å¤§ç­‰å¾…æ—¶é—´ï¼ˆç§’ï¼‰
        """
        wait_time = random.uniform(min_seconds, max_seconds)
        logger.debug(f"éšæœºç­‰å¾… {wait_time:.2f} ç§’...")
        time.sleep(wait_time)
    
    def retry_with_backoff(self, func, max_retries: int = 3, base_delay: float = 1.0, 
                          backoff_factor: float = 2.0, *args, **kwargs):
        """
        å¸¦æŒ‡æ•°é€€é¿çš„é‡è¯•æœºåˆ¶
        
        Args:
            func: è¦é‡è¯•çš„å‡½æ•°
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°ï¼ˆé»˜è®¤3æ¬¡ï¼‰
            base_delay: åŸºç¡€å»¶è¿Ÿæ—¶é—´ï¼ˆç§’ï¼‰
            backoff_factor: é€€é¿å› å­ï¼ˆé»˜è®¤2ï¼Œå³1s, 2s, 4sï¼‰
            *args, **kwargs: ä¼ é€’ç»™å‡½æ•°çš„å‚æ•°
            
        Returns:
            å‡½æ•°æ‰§è¡Œç»“æœ
            
        Raises:
            æœ€åä¸€æ¬¡å°è¯•çš„å¼‚å¸¸
        """
        last_exception = None
        
        for attempt in range(max_retries):
            try:
                return func(*args, **kwargs)
            except (PlaywrightTimeoutError, Exception) as e:
                last_exception = e
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯å¯é‡è¯•çš„é”™è¯¯
                error_str = str(e).lower()
                retriable_errors = [
                    'timeout',
                    'network',
                    'connection',
                    'navigation',
                    'page.goto',
                    'load state',
                ]
                
                is_retriable = any(keyword in error_str for keyword in retriable_errors)
                
                if not is_retriable:
                    # ä¸å¯é‡è¯•çš„é”™è¯¯ï¼Œç›´æ¥æŠ›å‡º
                    logger.error(f"é‡åˆ°ä¸å¯é‡è¯•çš„é”™è¯¯: {str(e)}")
                    raise
                
                if attempt < max_retries - 1:
                    # è®¡ç®—å»¶è¿Ÿæ—¶é—´ï¼ˆæŒ‡æ•°é€€é¿ï¼‰
                    delay = base_delay * (backoff_factor ** attempt)
                    logger.warning(f"âš ï¸ ç½‘ç»œé”™è¯¯ï¼ˆå°è¯• {attempt + 1}/{max_retries}ï¼‰: {str(e)[:100]}")
                    logger.info(f"ç­‰å¾… {delay:.1f} ç§’åé‡è¯•...")
                    time.sleep(delay)
                else:
                    logger.error(f"âŒ é‡è¯• {max_retries} æ¬¡åä»ç„¶å¤±è´¥: {str(e)}")
        
        # æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥ï¼ŒæŠ›å‡ºæœ€åä¸€æ¬¡çš„å¼‚å¸¸
        raise last_exception
    
    def save_cookies(self, page: Page) -> bool:
        """
        ä¿å­˜å½“å‰é¡µé¢çš„ Cookies åˆ°æ–‡ä»¶
        
        Args:
            page: Playwright Page å¯¹è±¡
            
        Returns:
            æ˜¯å¦ä¿å­˜æˆåŠŸ
        """
        try:
            cookies = page.context.cookies()
            auth_data = {
                'cookies': cookies,
                'user_agent': self.user_agent,
                'saved_at': time.strftime('%Y-%m-%d %H:%M:%S')
            }
            
            with open(self.auth_file, 'w', encoding='utf-8') as f:
                json.dump(auth_data, f, ensure_ascii=False, indent=2)
            
            logger.info(f"âœ… Cookies å·²ä¿å­˜åˆ°: {self.auth_file}")
            return True
        except Exception as e:
            logger.error(f"ä¿å­˜ Cookies å¤±è´¥: {str(e)}")
            return False
    
    def load_cookies(self, page: Page) -> bool:
        """
        ä»æ–‡ä»¶åŠ è½½ Cookies åˆ°é¡µé¢ä¸Šä¸‹æ–‡
        
        Args:
            page: Playwright Page å¯¹è±¡
            
        Returns:
            æ˜¯å¦åŠ è½½æˆåŠŸ
        """
        if not self.auth_file.exists():
            logger.warning(f"è®¤è¯æ–‡ä»¶ä¸å­˜åœ¨: {self.auth_file}")
            return False
        
        try:
            with open(self.auth_file, 'r', encoding='utf-8') as f:
                auth_data = json.load(f)
            
            cookies = auth_data.get('cookies', [])
            if not cookies:
                logger.warning("è®¤è¯æ–‡ä»¶ä¸­æ²¡æœ‰ Cookies æ•°æ®")
                return False
            
            # å…ˆè®¿é—®æ·˜å®é¦–é¡µï¼Œå»ºç«‹åŸŸåä¸Šä¸‹æ–‡
            page.goto('https://www.taobao.com', timeout=30000, wait_until='domcontentloaded')
            page.wait_for_timeout(1000)
            
            # åŠ è½½ Cookies
            page.context.add_cookies(cookies)
            
            # å¦‚æœæœ‰ä¿å­˜çš„ User-Agentï¼Œä½¿ç”¨å®ƒ
            saved_ua = auth_data.get('user_agent')
            if saved_ua:
                self.user_agent = saved_ua
                # è®¾ç½® User-Agentï¼ˆé€šè¿‡ context è®¾ç½®ï¼‰
                page.set_extra_http_headers({'User-Agent': self.user_agent})
            
            logger.info(f"âœ… Cookies å·²åŠ è½½ (ä¿å­˜æ—¶é—´: {auth_data.get('saved_at', 'æœªçŸ¥')})")
            return True
        except Exception as e:
            logger.error(f"åŠ è½½ Cookies å¤±è´¥: {str(e)}")
            return False
    
    def is_cookies_expired(self, page: Page) -> bool:
        """
        æ£€æŸ¥ Cookies æ˜¯å¦å¤±æ•ˆï¼ˆé€šè¿‡æ£€æŸ¥æ˜¯å¦è¢«é‡å®šå‘åˆ°ç™»å½•é¡µï¼‰
        
        Args:
            page: Playwright Page å¯¹è±¡
            
        Returns:
            True è¡¨ç¤º Cookies å·²å¤±æ•ˆï¼ŒFalse è¡¨ç¤ºæ­£å¸¸
        """
        try:
            current_url = page.url
            # æ£€æŸ¥æ˜¯å¦è¢«é‡å®šå‘åˆ°ç™»å½•é¡µ
            login_url_patterns = [
                'login.taobao.com',
                'passport.taobao.com',
                '/member/login',
            ]
            
            for pattern in login_url_patterns:
                if pattern in current_url:
                    logger.warning(f"æ£€æµ‹åˆ°ç™»å½•é¡µURLï¼ŒCookieså¯èƒ½å·²å¤±æ•ˆ: {current_url}")
                    return True
            
            # æ£€æŸ¥é¡µé¢å†…å®¹ä¸­æ˜¯å¦åŒ…å«ç™»å½•æç¤º
            try:
                page_content = page.content()
                login_indicators = [
                    'è¯·ç™»å½•',
                    'ç™»å½•å',
                    'æ‰«ç ç™»å½•',
                    'è´¦å·ç™»å½•',
                ]
                # æ£€æŸ¥é¡µé¢æ ‡é¢˜æˆ–å…³é”®åŒºåŸŸ
                for indicator in login_indicators:
                    if indicator in page_content[:5000]:  # åªæ£€æŸ¥å‰5000å­—ç¬¦
                        # è¿›ä¸€æ­¥ç¡®è®¤ï¼šæ£€æŸ¥æ˜¯å¦åœ¨ç™»å½•è¡¨å•åŒºåŸŸ
                        login_form = page.query_selector('form[action*="login"], .login-form, #login-form')
                        if login_form:
                            logger.warning(f"æ£€æµ‹åˆ°ç™»å½•è¡¨å•ï¼ŒCookieså¯èƒ½å·²å¤±æ•ˆ")
                            return True
            except:
                pass
            
            return False
            
        except Exception as e:
            logger.debug(f"æ£€æŸ¥Cookieså¤±æ•ˆçŠ¶æ€æ—¶å‡ºé”™: {str(e)}")
            return False
    
    def is_logged_in(self, page: Page) -> bool:
        """
        æ£€æŸ¥æ˜¯å¦å·²ç™»å½•ï¼ˆé€šè¿‡æ£€æŸ¥é¡µé¢å…ƒç´ åˆ¤æ–­ï¼‰
        
        Args:
            page: Playwright Page å¯¹è±¡
            
        Returns:
            æ˜¯å¦å·²ç™»å½•
        """
        try:
            # é¦–å…ˆæ£€æŸ¥ Cookies æ˜¯å¦å¤±æ•ˆ
            if self.is_cookies_expired(page):
                logger.warning("âš ï¸ Cookies å·²å¤±æ•ˆï¼Œéœ€è¦é‡æ–°ç™»å½•")
                return False
            
            # è®¿é—®æ·˜å®é¦–é¡µï¼Œå…è®¸å¯¼èˆªä¸­æ–­ï¼ˆç™»å½•åä¼šè‡ªåŠ¨è·³è½¬åˆ°"æˆ‘çš„æ·˜å®"ï¼‰
            # ä½¿ç”¨ domcontentloaded è€Œä¸æ˜¯ networkidleï¼Œé¿å…è¶…æ—¶
            try:
                page.goto('https://www.taobao.com', timeout=60000, wait_until='domcontentloaded')
                # ç­‰å¾…ç½‘ç»œç©ºé—²ï¼Œä½†è®¾ç½®è¾ƒçŸ­çš„è¶…æ—¶ï¼ˆä¸å¼ºåˆ¶è¦æ±‚ï¼‰
                try:
                    page.wait_for_load_state('networkidle', timeout=10000)
                except PlaywrightTimeoutError:
                    logger.debug("ç½‘ç»œæœªå®Œå…¨ç©ºé—²ï¼Œä½†é¡µé¢å·²åŠ è½½ï¼Œç»§ç»­æ£€æŸ¥")
            except PlaywrightTimeoutError as nav_error:
                # è¶…æ—¶æ—¶ä¹Ÿç»§ç»­ï¼Œå¯èƒ½é¡µé¢å·²ç»åŠ è½½äº†åŸºæœ¬å†…å®¹
                logger.debug(f"é¡µé¢åŠ è½½è¶…æ—¶ï¼Œä½†ç»§ç»­æ£€æŸ¥ç™»å½•çŠ¶æ€: {str(nav_error)[:100]}")
                page.wait_for_timeout(2000)  # ç­‰å¾…ä¸€ä¸‹è®©é¡µé¢ç¨³å®š
            except Exception as nav_error:
                # å¦‚æœæ˜¯å¯¼èˆªä¸­æ–­å¼‚å¸¸ï¼Œå¯èƒ½æ˜¯ç™»å½•åçš„è‡ªåŠ¨è·³è½¬ï¼Œå…ˆç­‰å¾…ä¸€ä¸‹
                if "interrupted" in str(nav_error).lower() or "navigation" in str(nav_error).lower():
                    logger.debug(f"æ£€æµ‹åˆ°å¯¼èˆªä¸­æ–­ï¼Œå¯èƒ½æ˜¯ç™»å½•åçš„è‡ªåŠ¨è·³è½¬: {nav_error}")
                    page.wait_for_timeout(3000)  # ç­‰å¾…è·³è½¬å®Œæˆ
                else:
                    logger.debug(f"å¯¼èˆªå‡ºç°å…¶ä»–å¼‚å¸¸ï¼Œç»§ç»­æ£€æŸ¥: {str(nav_error)[:100]}")
                    page.wait_for_timeout(2000)
            
            # å†æ¬¡æ£€æŸ¥ Cookies æ˜¯å¦å¤±æ•ˆï¼ˆå¯èƒ½åœ¨å¯¼èˆªåå¤±æ•ˆï¼‰
            if self.is_cookies_expired(page):
                logger.warning("âš ï¸ Cookies å·²å¤±æ•ˆï¼ˆå¯¼èˆªåæ£€æµ‹ï¼‰ï¼Œéœ€è¦é‡æ–°ç™»å½•")
                return False
            
            # ç­‰å¾…é¡µé¢ç¨³å®š
            page.wait_for_timeout(2000)
            
            # æ–¹æ³•1: æ£€æŸ¥å½“å‰ URLï¼ˆå¦‚æœè·³è½¬åˆ°"æˆ‘çš„æ·˜å®"ï¼Œè¯´æ˜å·²ç™»å½•ï¼‰
            current_url = page.url
            if 'i.taobao.com/my_taobao' in current_url or 'i.taobao.com' in current_url:
                logger.debug(f"æ£€æµ‹åˆ°è·³è½¬åˆ°æˆ‘çš„æ·˜å®é¡µé¢ï¼Œå·²ç™»å½•: {current_url}")
                return True
            
            # æ–¹æ³•2: æ£€æŸ¥æ˜¯å¦å­˜åœ¨ç™»å½•åçš„å…ƒç´ ï¼ˆå¦‚ç”¨æˆ·æ˜µç§°ã€è´­ç‰©è½¦ç­‰ï¼‰
            logged_in_indicators = [
                '.site-nav-user a[href*="member"]',  # ä¼šå‘˜ä¸­å¿ƒé“¾æ¥
                '.site-nav-user .username',  # ç”¨æˆ·å
                '.h-member-name',  # ä¼šå‘˜å
                '.site-nav-login .h',  # ç™»å½•åçš„ç”¨æˆ·ååŒºåŸŸ
            ]
            
            for selector in logged_in_indicators:
                try:
                    element = page.query_selector(selector)
                    if element:
                        text = element.inner_text().strip()
                        # å¦‚æœå…ƒç´ æœ‰æ–‡æœ¬ä¸”ä¸æ˜¯"ç™»å½•"æˆ–"å…è´¹æ³¨å†Œ"ï¼Œè¯´æ˜å·²ç™»å½•
                        if text and 'ç™»å½•' not in text and 'å…è´¹æ³¨å†Œ' not in text:
                            logger.debug(f"æ£€æµ‹åˆ°ç™»å½•å…ƒç´ : {selector} = {text}")
                            return True
                except:
                    continue
            
            # æ–¹æ³•3: æ£€æŸ¥æ˜¯å¦å­˜åœ¨ç™»å½•æŒ‰é’®ï¼ˆå¦‚æœå­˜åœ¨ä¸”å¯è§ï¼Œè¯´æ˜æœªç™»å½•ï¼‰
            try:
                login_button = page.query_selector('.site-nav-login a[href*="login"]:visible')
                if login_button:
                    text = login_button.inner_text().strip()
                    if 'ç™»å½•' in text or 'å…è´¹æ³¨å†Œ' in text:
                        logger.debug("æ£€æµ‹åˆ°ç™»å½•æŒ‰é’®ï¼Œæœªç™»å½•çŠ¶æ€")
                        return False
            except:
                pass
            
            # æ–¹æ³•4: æ£€æŸ¥ Cookies ä¸­æ˜¯å¦æœ‰ç™»å½•ç›¸å…³çš„ Cookie
            cookies = page.context.cookies()
            login_cookies = [c for c in cookies if 't' in c.get('name', '').lower() or 'lgc' in c.get('name', '').lower() or 'cna' in c.get('name', '').lower()]
            if len(login_cookies) > 0:
                logger.debug(f"æ£€æµ‹åˆ°ç™»å½•ç›¸å…³çš„ Cookiesï¼Œå‡è®¾å·²ç™»å½•ï¼ˆ{len(login_cookies)} ä¸ªï¼‰")
                return True
            
            # å¦‚æœéƒ½ä¸ç¡®å®šï¼Œä¿å®ˆç­–ç•¥ï¼šå‡è®¾å·²ç™»å½•ï¼ˆå› ä¸ºå¯èƒ½æœ‰ Cookiesï¼‰
            logger.warning("æ— æ³•æ˜ç¡®åˆ¤æ–­ç™»å½•çŠ¶æ€ï¼Œå‡è®¾å·²ç™»å½•ï¼ˆä¿å®ˆç­–ç•¥ï¼‰")
            return True
            
        except Exception as e:
            # å³ä½¿å‡ºé”™ï¼Œä¹Ÿæ£€æŸ¥ URL å’Œ Cookies
            try:
                current_url = page.url
                if 'i.taobao.com' in current_url:
                    logger.debug(f"å³ä½¿å‡ºé”™ï¼Œæ£€æµ‹åˆ°æˆ‘çš„æ·˜å®URLï¼Œå·²ç™»å½•: {current_url}")
                    return True
                # æ£€æŸ¥æ˜¯å¦åœ¨ç™»å½•é¡µ
                if self.is_cookies_expired(page):
                    logger.warning("âš ï¸ Cookies å·²å¤±æ•ˆï¼Œéœ€è¦é‡æ–°ç™»å½•")
                    return False
            except:
                pass
            
            logger.warning(f"æ£€æŸ¥ç™»å½•çŠ¶æ€æ—¶å‡ºé”™: {str(e)}ï¼Œå‡è®¾å·²ç™»å½•")
            return True  # å‡ºé”™æ—¶å‡è®¾å·²ç™»å½•ï¼Œè®©åç»­æµç¨‹ç»§ç»­
    
    def setup_login(self, interactive: bool = True) -> bool:
        """
        è®¾ç½®ç™»å½•ï¼ˆæŒä¹…åŒ–ç™»å½•çš„æ ¸å¿ƒå‡½æ•°ï¼‰
        - å¦‚æœæœ¬åœ°æ²¡æœ‰ auth_taobao.jsonï¼Œå¼¹å‡ºæµè§ˆå™¨è®©ç”¨æˆ·æ‰«ç ç™»å½•ï¼Œç„¶åä¿å­˜ Cookies
        - å¦‚æœæœ‰ï¼Œå°±ç›´æ¥åŠ è½½ Cookies
        
        Args:
            interactive: æ˜¯å¦äº¤äº’æ¨¡å¼ï¼ˆTrue æ—¶ç­‰å¾…ç”¨æˆ·è¾“å…¥ Enterï¼ŒFalse æ—¶è‡ªåŠ¨æ£€æµ‹ç™»å½•å®Œæˆï¼‰
        
        Returns:
            æ˜¯å¦ç™»å½•æˆåŠŸ
        """
        logger.info("=" * 60)
        logger.info("æ·˜å®ç™»å½•è®¾ç½®")
        logger.info("=" * 60)
        
        with sync_playwright() as p:
            # å¯åŠ¨æµè§ˆå™¨ï¼ˆç™»å½•æ—¶ä½¿ç”¨éæ— å¤´æ¨¡å¼ï¼Œæ–¹ä¾¿æ‰«ç ï¼‰
            browser = p.chromium.launch(
                headless=False,  # ç™»å½•æ—¶å¿…é¡»æ˜¾ç¤ºæµè§ˆå™¨çª—å£
                args=[
                    '--disable-blink-features=AutomationControlled',  # éšè—è‡ªåŠ¨åŒ–ç‰¹å¾
                    '--disable-dev-shm-usage',
                    '--no-sandbox',
                ]
            )
            
            context = browser.new_context(
                viewport=self.viewport,
                user_agent=self.user_agent,
                # è®¾ç½®è¯­è¨€å’Œåœ°åŒºï¼ˆæ¨¡æ‹ŸçœŸå®ç”¨æˆ·ï¼‰
                locale='zh-CN',
                timezone_id='Asia/Shanghai',
            )
            
            page = context.new_page()
            
            # æ³¨å…¥ JavaScript éšè— webdriver ç‰¹å¾
            page.add_init_script("""
                Object.defineProperty(navigator, 'webdriver', {
                    get: () => undefined
                });
                // æ·»åŠ  Chrome ç‰¹å¾
                window.chrome = {
                    runtime: {}
                };
                // è¦†ç›– permissions API
                const originalQuery = window.navigator.permissions.query;
                window.navigator.permissions.query = (parameters) => (
                    parameters.name === 'notifications' ?
                        Promise.resolve({ state: Notification.permission }) :
                        originalQuery(parameters)
                );
            """)
            
            try:
                # æƒ…å†µ1: å¦‚æœè®¤è¯æ–‡ä»¶å­˜åœ¨ï¼Œå°è¯•åŠ è½½ Cookies
                if self.auth_file.exists():
                    logger.info(f"å‘ç°è®¤è¯æ–‡ä»¶: {self.auth_file}")
                    logger.info("æ­£åœ¨åŠ è½½å·²ä¿å­˜çš„ Cookies...")
                    
                    if self.load_cookies(page):
                        # ç­‰å¾…ä¸€ä¸‹è®© Cookies ç”Ÿæ•ˆ
                        page.wait_for_timeout(2000)
                        
                        # éªŒè¯æ˜¯å¦ç™»å½•æˆåŠŸ
                        logger.info("æ­£åœ¨éªŒè¯ç™»å½•çŠ¶æ€...")
                        if self.is_logged_in(page):
                            logger.info("âœ… ç™»å½•æˆåŠŸï¼ˆä½¿ç”¨å·²ä¿å­˜çš„ Cookiesï¼‰")
                            browser.close()
                            return True
                        else:
                            logger.warning("âš ï¸ å·²ä¿å­˜çš„ Cookies å·²å¤±æ•ˆï¼Œéœ€è¦é‡æ–°ç™»å½•")
                    else:
                        logger.warning("âš ï¸ åŠ è½½ Cookies å¤±è´¥ï¼Œéœ€è¦é‡æ–°ç™»å½•")
                else:
                    logger.info("æœªæ‰¾åˆ°è®¤è¯æ–‡ä»¶ï¼Œéœ€è¦é¦–æ¬¡ç™»å½•")
                
                # æƒ…å†µ2: éœ€è¦é‡æ–°ç™»å½•æˆ–é¦–æ¬¡ç™»å½•
                logger.info("=" * 60)
                logger.info("è¯·åœ¨æµè§ˆå™¨ä¸­å®Œæˆç™»å½•ï¼š")
                logger.info("1. å¦‚æœå‡ºç°äºŒç»´ç ï¼Œè¯·ä½¿ç”¨æ‰‹æœºæ·˜å®æ‰«ç ç™»å½•")
                logger.info("2. ç™»å½•æˆåŠŸåï¼Œè¯·åœ¨æµè§ˆå™¨ä¸­è®¿é—®ä»»æ„é¡µé¢ç¡®è®¤")
                logger.info("3. ç™»å½•å®Œæˆåï¼Œè¯·å›åˆ°ç»ˆç«¯æŒ‰ Enter ç»§ç»­...")
                logger.info("=" * 60)
                
                # è®¿é—®æ·˜å®ç™»å½•é¡µï¼ˆä½¿ç”¨ networkidle æ›´å®½æ¾çš„ç­‰å¾…ç­–ç•¥ï¼‰
                try:
                    page.goto('https://login.taobao.com/member/login.jhtml', timeout=60000, wait_until='networkidle')
                except Exception as e:
                    # å¦‚æœå¯¼èˆªè¢«ä¸­æ–­ï¼ˆæ¯”å¦‚è‡ªåŠ¨è·³è½¬ï¼‰ï¼Œç»§ç»­ç­‰å¾…
                    if "interrupted" in str(e).lower():
                        logger.debug("ç™»å½•é¡µå¯¼èˆªè¢«ä¸­æ–­ï¼Œå¯èƒ½æ˜¯è‡ªåŠ¨è·³è½¬")
                    else:
                        logger.warning(f"è®¿é—®ç™»å½•é¡µæ—¶å‡ºç°é—®é¢˜: {e}")
                page.wait_for_timeout(2000)
                
                # ç­‰å¾…ç”¨æˆ·æ‰‹åŠ¨ç™»å½•
                logger.info("ç­‰å¾…ç”¨æˆ·ç™»å½•...")
                logger.info("æç¤ºï¼šç™»å½•åå¦‚æœé¡µé¢è‡ªåŠ¨è·³è½¬ï¼Œè¯´æ˜ç™»å½•æˆåŠŸ")
                
                if interactive:
                    # äº¤äº’æ¨¡å¼ï¼šç­‰å¾…ç”¨æˆ·è¾“å…¥
                    input("ç™»å½•å®Œæˆåï¼ŒæŒ‰ Enter ç»§ç»­...")
                else:
                    # éäº¤äº’æ¨¡å¼ï¼šè‡ªåŠ¨æ£€æµ‹ç™»å½•å®Œæˆ
                    logger.info("è‡ªåŠ¨æ£€æµ‹ç™»å½•çŠ¶æ€...")
                    max_wait_time = 300  # æœ€å¤šç­‰å¾… 5 åˆ†é’Ÿ
                    check_interval = 3  # æ¯ 3 ç§’æ£€æŸ¥ä¸€æ¬¡
                    start_time = time.time()
                    
                    while time.time() - start_time < max_wait_time:
                        page.wait_for_timeout(check_interval * 1000)
                        
                        # æ£€æŸ¥æ˜¯å¦å·²ç™»å½•
                        try:
                            if self.is_logged_in(page):
                                logger.info("âœ… æ£€æµ‹åˆ°ç™»å½•æˆåŠŸï¼")
                                break
                        except:
                            pass
                        
                        # æ£€æŸ¥å½“å‰ URL æ˜¯å¦å·²è·³è½¬ï¼ˆè¯´æ˜ç™»å½•æˆåŠŸï¼‰
                        current_url = page.url
                        if 'login.taobao.com' not in current_url and 'passport.taobao.com' not in current_url:
                            # ä¸åœ¨ç™»å½•é¡µäº†ï¼Œå¯èƒ½æ˜¯ç™»å½•æˆåŠŸ
                            logger.info(f"æ£€æµ‹åˆ°é¡µé¢è·³è½¬: {current_url}")
                            page.wait_for_timeout(2000)  # ç­‰å¾…é¡µé¢ç¨³å®š
                            if self.is_logged_in(page):
                                logger.info("âœ… æ£€æµ‹åˆ°ç™»å½•æˆåŠŸï¼")
                                break
                        
                        elapsed = int(time.time() - start_time)
                        if elapsed % 15 == 0:  # æ¯ 15 ç§’æç¤ºä¸€æ¬¡
                            logger.info(f"ç­‰å¾…ç™»å½•ä¸­... ({elapsed}/{max_wait_time} ç§’)")
                    else:
                        # è¶…æ—¶
                        logger.warning(f"âš ï¸ ç­‰å¾…ç™»å½•è¶…æ—¶ï¼ˆ{max_wait_time} ç§’ï¼‰ï¼Œå°†æ£€æŸ¥å½“å‰çŠ¶æ€...")
                
                # ç­‰å¾…ä¸€ä¸‹è®©é¡µé¢ç¨³å®šï¼ˆå¦‚æœæ˜¯è‡ªåŠ¨è·³è½¬ï¼Œéœ€è¦æ—¶é—´ï¼‰
                page.wait_for_timeout(3000)
                
                # å†æ¬¡éªŒè¯ç™»å½•çŠ¶æ€
                logger.info("æ­£åœ¨éªŒè¯ç™»å½•çŠ¶æ€...")
                if self.is_logged_in(page):
                    logger.info("âœ… ç™»å½•éªŒè¯æˆåŠŸï¼")
                    
                    # ä¿å­˜ Cookies
                    if self.save_cookies(page):
                        logger.info("âœ… ç™»å½•ä¿¡æ¯å·²ä¿å­˜ï¼Œä¸‹æ¬¡å¯ä»¥ç›´æ¥ä½¿ç”¨")
                        browser.close()
                        return True
                    else:
                        logger.error("âš ï¸ ç™»å½•æˆåŠŸï¼Œä½†ä¿å­˜ Cookies å¤±è´¥")
                        browser.close()
                        return False
                else:
                    logger.error("âŒ ç™»å½•éªŒè¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ˜¯å¦å·²æˆåŠŸç™»å½•")
                    logger.info("æç¤ºï¼šå¦‚æœç¡®å®å·²ç™»å½•ï¼Œå¯èƒ½æ˜¯å› ä¸ºéªŒè¯é€»è¾‘é—®é¢˜ï¼Œå¯ä»¥å°è¯•é‡æ–°è¿è¡Œ")
                    browser.close()
                    return False
                    
            except KeyboardInterrupt:
                logger.info("\nç”¨æˆ·ä¸­æ–­ç™»å½•æµç¨‹")
                browser.close()
                return False
            except Exception as e:
                logger.error(f"ç™»å½•è¿‡ç¨‹å‡ºé”™: {str(e)}", exc_info=True)
                browser.close()
                return False
    
    def create_browser_context(self, playwright):
        """
        åˆ›å»ºæµè§ˆå™¨ä¸Šä¸‹æ–‡ï¼ˆç”¨äºåç»­çš„çˆ¬å–ä»»åŠ¡ï¼‰
        
        Args:
            playwright: Playwright å®ä¾‹
            
        Returns:
            (browser, context, page) å…ƒç»„
        """
        browser = playwright.chromium.launch(
            headless=self.headless,
            args=[
                '--disable-blink-features=AutomationControlled',
                '--disable-dev-shm-usage',
                '--no-sandbox',
            ]
        )
        
        context = browser.new_context(
            viewport=self.viewport,
            user_agent=self.user_agent,
            locale='zh-CN',
            timezone_id='Asia/Shanghai',
        )
        
        page = context.new_page()
        
        # æ³¨å…¥ JavaScript éšè— webdriver ç‰¹å¾
        page.add_init_script("""
            Object.defineProperty(navigator, 'webdriver', {
                get: () => undefined
            });
            window.chrome = { runtime: {} };
            const originalQuery = window.navigator.permissions.query;
            window.navigator.permissions.query = (parameters) => (
                parameters.name === 'notifications' ?
                    Promise.resolve({ state: Notification.permission }) :
                    originalQuery(parameters)
            );
        """)
        
        # åŠ è½½å·²ä¿å­˜çš„ Cookiesï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if self.auth_file.exists():
            self.load_cookies(page)
        
        return browser, context, page
    
    def check_and_handle_captcha(self, page: Page, timeout: int = 60) -> bool:
        """
        æ£€æŸ¥å¹¶å¤„ç†éªŒè¯ç /æ»‘å—
        
        Args:
            page: Playwright Page å¯¹è±¡
            timeout: ç­‰å¾…è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤60ç§’
            
        Returns:
            æ˜¯å¦æˆåŠŸå¤„ç†ï¼ˆFalseè¡¨ç¤ºè¶…æ—¶æˆ–å¤±è´¥ï¼‰
        """
        # éªŒè¯ç /æ»‘å—çš„å¤šä¸ªå¯èƒ½é€‰æ‹©å™¨
        captcha_selectors = [
            '.nc_iconfont',  # æ»‘å—éªŒè¯ç 
            '.baxia-dialog',  # éªŒè¯ç å¼¹çª—
            '#nocaptcha',  # æ— éªŒè¯ç æ ‡è¯†ï¼ˆä½†å¯èƒ½æ˜¯éªŒè¯ç å®¹å™¨ï¼‰
            '.nc-wrapper',  # æ»‘å—éªŒè¯ç å®¹å™¨
            '.slider',  # æ»‘å—
            '[class*="captcha"]',  # åŒ…å«captchaçš„ç±»
            '[class*="verify"]',  # åŒ…å«verifyçš„ç±»
        ]
        
        try:
            # ç­‰å¾…ä¸€å°æ®µæ—¶é—´ï¼Œè®©éªŒè¯ç å…ƒç´ æœ‰æœºä¼šåŠ è½½
            page.wait_for_timeout(2000)
            
            # æ£€æŸ¥æ˜¯å¦å­˜åœ¨éªŒè¯ç å…ƒç´ 
            captcha_element = None
            for selector in captcha_selectors:
                try:
                    captcha_element = page.query_selector(selector)
                    if captcha_element and captcha_element.is_visible():
                        logger.warning(f"âš ï¸ æ£€æµ‹åˆ°éªŒè¯ç å…ƒç´ : {selector}")
                        break
                except:
                    continue
            
            if not captcha_element:
                # ä¹Ÿæ£€æŸ¥é¡µé¢URLæ˜¯å¦åŒ…å«éªŒè¯ç›¸å…³è·¯å¾„
                current_url = page.url
                if 'verify' in current_url.lower() or 'captcha' in current_url.lower():
                    logger.warning(f"âš ï¸ æ£€æµ‹åˆ°éªŒè¯ç é¡µé¢URL: {current_url}")
                    captcha_element = True  # æ ‡è®°ä¸ºå­˜åœ¨
            
            if captcha_element:
                logger.warning("=" * 60)
                logger.warning("âš ï¸ æ£€æµ‹åˆ°éªŒè¯ç /æ»‘å—ï¼Œéœ€è¦äººå·¥å¤„ç†")
                logger.warning("è¯·åœ¨æµè§ˆå™¨ä¸­å®ŒæˆéªŒè¯ï¼Œè„šæœ¬å°†ç­‰å¾…éªŒè¯å®Œæˆ...")
                logger.warning(f"ç­‰å¾…è¶…æ—¶æ—¶é—´: {timeout} ç§’")
                logger.warning("=" * 60)
                
                # è½®è¯¢æ£€æŸ¥éªŒè¯ç æ˜¯å¦æ¶ˆå¤±ï¼ˆæ¯2ç§’æ£€æŸ¥ä¸€æ¬¡ï¼‰
                start_time = time.time()
                check_interval = 2  # æ¯2ç§’æ£€æŸ¥ä¸€æ¬¡
                
                while time.time() - start_time < timeout:
                    # æ£€æŸ¥éªŒè¯ç å…ƒç´ æ˜¯å¦è¿˜å­˜åœ¨
                    captcha_still_exists = False
                    for selector in captcha_selectors:
                        try:
                            elem = page.query_selector(selector)
                            if elem and elem.is_visible():
                                captcha_still_exists = True
                                break
                        except:
                            continue
                    
                    # æ£€æŸ¥URLæ˜¯å¦è¿˜æ˜¯éªŒè¯é¡µé¢
                    if not captcha_still_exists:
                        current_url = page.url
                        if 'verify' not in current_url.lower() and 'captcha' not in current_url.lower():
                            logger.info("âœ… éªŒè¯ç å·²å¤„ç†å®Œæˆï¼Œç»§ç»­æ‰§è¡Œ...")
                            page.wait_for_timeout(1000)  # ç­‰å¾…é¡µé¢ç¨³å®š
                            return True
                    
                    # ç­‰å¾…åå†æ¬¡æ£€æŸ¥
                    page.wait_for_timeout(check_interval * 1000)
                    
                    elapsed = int(time.time() - start_time)
                    if elapsed % 10 == 0:  # æ¯10ç§’æç¤ºä¸€æ¬¡
                        logger.info(f"ç­‰å¾…éªŒè¯ä¸­... ({elapsed}/{timeout} ç§’)")
                
                # è¶…æ—¶
                logger.error(f"âŒ éªŒè¯ç å¤„ç†è¶…æ—¶ï¼ˆ{timeout} ç§’ï¼‰ï¼Œè·³è¿‡å½“å‰é¡µé¢")
                return False
            
            return True  # æ²¡æœ‰éªŒè¯ç ï¼Œæ­£å¸¸ç»§ç»­
            
        except Exception as e:
            logger.error(f"æ£€æŸ¥éªŒè¯ç æ—¶å‡ºé”™: {str(e)}")
            return True  # å‡ºé”™æ—¶å‡è®¾æ²¡æœ‰éªŒè¯ç ï¼Œç»§ç»­æ‰§è¡Œ
    
    def _search_keyword_internal(self, page: Page, keyword: str) -> bool:
        """
        æœç´¢å…³é”®è¯çš„å†…éƒ¨å®ç°ï¼ˆç”¨äºé‡è¯•ï¼‰
        """
        logger.info(f"æœç´¢å…³é”®è¯: {keyword}")
        
        # è®¿é—®æ·˜å®æœç´¢é¡µï¼ˆå¢åŠ è¶…æ—¶æ—¶é—´ï¼‰
        search_url = f"https://s.taobao.com/search?q={keyword}"
        try:
            page.goto(search_url, timeout=60000, wait_until='domcontentloaded')
            # ç­‰å¾…ç½‘ç»œç©ºé—²ï¼Œä½†è®¾ç½®è¾ƒé•¿çš„è¶…æ—¶
            page.wait_for_load_state('networkidle', timeout=30000)
        except PlaywrightTimeoutError as e:
            logger.warning(f"é¡µé¢åŠ è½½å¯èƒ½æœªå®Œå…¨å®Œæˆï¼Œç»§ç»­å°è¯•: {str(e)[:100]}")
            # å³ä½¿è¶…æ—¶ä¹Ÿç»§ç»­ï¼Œå¯èƒ½ç½‘ç»œæ…¢ä½†é¡µé¢åŸºæœ¬åŠ è½½äº†
        
        # ç­‰å¾…é¡µé¢ç¨³å®š
        self.wait_random(2.0, 3.0)
        
        # æ£€æŸ¥æ˜¯å¦è¢«é‡å®šå‘åˆ°ç™»å½•é¡µæˆ–é”™è¯¯é¡µ
        current_url = page.url
        if 'login.taobao.com' in current_url or 'passport.taobao.com' in current_url:
            logger.error(f"è¢«é‡å®šå‘åˆ°ç™»å½•é¡µ: {current_url}")
            raise Exception("éœ€è¦é‡æ–°ç™»å½•")
        
        # æ£€æŸ¥å¹¶å¤„ç†éªŒè¯ç ï¼ˆå¢åŠ ç­‰å¾…æ—¶é—´ï¼‰
        if not self.check_and_handle_captcha(page, timeout=60):
            logger.warning("éªŒè¯ç å¤„ç†å¤±è´¥æˆ–è¶…æ—¶ï¼Œä½†ç»§ç»­å°è¯•...")
        
        # æ»šåŠ¨é¡µé¢ä»¥è§¦å‘æ‡’åŠ è½½ï¼ˆæ·˜å®æœç´¢ç»“æœå¯èƒ½æ˜¯æ‡’åŠ è½½çš„ï¼‰
        logger.debug("æ»šåŠ¨é¡µé¢ä»¥è§¦å‘å•†å“æ‡’åŠ è½½...")
        try:
            # å…ˆæ»šåŠ¨åˆ°åº•éƒ¨
            page.evaluate("window.scrollTo(0, document.body.scrollHeight)")
            page.wait_for_timeout(2000)
            # å†æ»šåŠ¨åˆ°ä¸­é—´
            page.evaluate("window.scrollTo(0, document.body.scrollHeight / 2)")
            page.wait_for_timeout(2000)
            # æ»šåŠ¨å›é¡¶éƒ¨
            page.evaluate("window.scrollTo(0, 0)")
            page.wait_for_timeout(2000)
        except Exception as e:
            logger.debug(f"æ»šåŠ¨æ“ä½œå¤±è´¥: {str(e)}")
        
        # ç­‰å¾…JavaScriptæ‰§è¡Œå®Œæˆï¼ˆæ·˜å®é¡µé¢å¤§é‡ä½¿ç”¨JSåŠ¨æ€åŠ è½½ï¼‰
        try:
            # ç­‰å¾…é¡µé¢JavaScriptæ‰§è¡Œå®Œæˆ
            page.wait_for_function(
                "document.readyState === 'complete'",
                timeout=10000
            )
        except PlaywrightTimeoutError:
            logger.debug("é¡µé¢JavaScriptæ‰§è¡Œå¯èƒ½æœªå®Œæˆï¼Œç»§ç»­å°è¯•...")
        
        # ç­‰å¾…æœç´¢ç»“æœåŠ è½½ï¼ˆä½¿ç”¨å¤šä¸ªé€‰æ‹©å™¨å’Œæ›´é•¿çš„è¶…æ—¶ï¼‰
        # æ·˜å®æœç´¢ç»“æœå¯èƒ½çš„å®¹å™¨é€‰æ‹©å™¨
        possible_selectors = [
            '.items .item',  # æ ‡å‡†é€‰æ‹©å™¨
            '.m-itemlist .items .item',  # å¯èƒ½çš„å®Œæ•´è·¯å¾„
            '[data-category="auctions"]',  # æ•°æ®å±æ€§
            '.item[data-category="auctions"]',  # ç»„åˆé€‰æ‹©å™¨
            '.item',  # æ›´é€šç”¨çš„é€‰æ‹©å™¨
        ]
        
        element_found = False
        for selector in possible_selectors:
            try:
                logger.debug(f"å°è¯•ç­‰å¾…é€‰æ‹©å™¨: {selector}")
                # ä½¿ç”¨ attached çŠ¶æ€è€Œä¸æ˜¯ visibleï¼Œå› ä¸ºå…ƒç´ å¯èƒ½åœ¨è§†å£å¤–
                page.wait_for_selector(selector, timeout=5000, state='attached')  # å‡å°‘è¶…æ—¶æ—¶é—´
                # éªŒè¯å…ƒç´ æ˜¯å¦çœŸçš„å­˜åœ¨
                elements = page.query_selector_all(selector)
                if elements and len(elements) > 0:
                    logger.info(f"âœ… æ‰¾åˆ°å•†å“å…ƒç´ : {selector} (å…± {len(elements)} ä¸ª)")
                    element_found = True
                    break
                else:
                    logger.debug(f"é€‰æ‹©å™¨ {selector} å­˜åœ¨ä½†æœªæ‰¾åˆ°å…ƒç´ ")
            except PlaywrightTimeoutError:
                logger.debug(f"é€‰æ‹©å™¨ {selector} è¶…æ—¶ï¼Œå°è¯•ä¸‹ä¸€ä¸ª")
                continue
        
        if not element_found:
            # å°è¯•æ£€æŸ¥é¡µé¢æ˜¯å¦æœ‰å†…å®¹ï¼ˆå¯èƒ½æ˜¯åçˆ¬è™«æ‹¦æˆªï¼‰
            try:
                page_content = page.content()
                page_text = page.inner_text('body') if page.query_selector('body') else ''
                
                # æ£€æŸ¥åçˆ¬è™«æ‹¦æˆª
                if 'éªŒè¯' in page_content or 'éªŒè¯ç ' in page_content:
                    logger.warning("âš ï¸ é¡µé¢å¯èƒ½åŒ…å«éªŒè¯ç ï¼Œä½†æœªè¢«æ£€æµ‹åˆ°")
                if 'è®¿é—®å¼‚å¸¸' in page_content or 'å®‰å…¨éªŒè¯' in page_content:
                    logger.error("âŒ é¡µé¢æ˜¾ç¤ºè®¿é—®å¼‚å¸¸æˆ–å®‰å…¨éªŒè¯")
                    raise Exception("è¢«åçˆ¬è™«æœºåˆ¶æ‹¦æˆª")
                
                # æ£€æŸ¥æ˜¯å¦æœ‰"æ²¡æœ‰æ‰¾åˆ°ç›¸å…³å•†å“"ç­‰æç¤º
                no_result_keywords = ['æ²¡æœ‰æ‰¾åˆ°', 'æš‚æ— å•†å“', 'æœç´¢ç»“æœä¸ºç©º', 'æœªæ‰¾åˆ°ç›¸å…³']
                if any(keyword in page_text for keyword in no_result_keywords):
                    logger.warning(f"âš ï¸ é¡µé¢æç¤ºæ²¡æœ‰æ‰¾åˆ°å•†å“")
                    raise Exception("æœç´¢ç»“æœä¸ºç©º")
                
                # æ£€æŸ¥é¡µé¢æ ‡é¢˜
                page_title = page.title()
                logger.info(f"å½“å‰é¡µé¢æ ‡é¢˜: {page_title}")
                logger.info(f"å½“å‰URL: {page.url}")
                
            except Exception as e:
                if "è¢«åçˆ¬è™«" in str(e) or "æœç´¢ç»“æœä¸ºç©º" in str(e):
                    raise
                logger.debug(f"é¡µé¢å†…å®¹æ£€æŸ¥å¤±è´¥: {str(e)}")
            
            # æœ€åå°è¯•ï¼šç›´æ¥æŸ¥è¯¢æ‰€æœ‰å¯èƒ½çš„å•†å“å…ƒç´ ï¼ˆä¸ç­‰å¾…ï¼‰
            logger.info("ğŸ” å°è¯•ç›´æ¥æŸ¥è¯¢å•†å“å…ƒç´ ...")
            try:
                # ç­‰å¾…é¡µé¢å†åŠ è½½ä¸€ä¸‹
                page.wait_for_timeout(2000)
                # å†æ¬¡æ»šåŠ¨è§¦å‘åŠ è½½
                page.evaluate("window.scrollTo(0, document.body.scrollHeight / 3)")
                page.wait_for_timeout(1500)
                
                # ç›´æ¥æŸ¥è¯¢å¤šç§å¯èƒ½çš„é€‰æ‹©å™¨
                test_selectors = [
                    '.item',
                    '[data-category="auctions"]',
                    '.items .item',
                    '.m-itemlist .items .item',
                ]
                
                for test_selector in test_selectors:
                    test_elements = page.query_selector_all(test_selector)
                    if test_elements and len(test_elements) > 0:
                        logger.info(f"âœ… ç›´æ¥æŸ¥è¯¢æ‰¾åˆ° {len(test_elements)} ä¸ªå•†å“å…ƒç´ ï¼ˆé€‰æ‹©å™¨: {test_selector}ï¼‰ï¼Œç»§ç»­æå–")
                        element_found = True
                        break
                
                if not element_found:
                    logger.warning("âš ï¸ ç›´æ¥æŸ¥è¯¢ä¹Ÿæœªæ‰¾åˆ°å•†å“å…ƒç´ ï¼Œä½†å°†ç»§ç»­å°è¯•æå–")
            except Exception as e:
                logger.debug(f"ç›´æ¥æŸ¥è¯¢å¤±è´¥: {str(e)}")
        
        # å³ä½¿æ²¡æ‰¾åˆ°æ ‡å‡†å…ƒç´ ï¼Œä¹Ÿç»§ç»­æ‰§è¡Œï¼ˆå¯èƒ½é¡µé¢ç»“æ„ä¸åŒï¼‰
        if not element_found:
            logger.warning("âš ï¸ æœªæ‰¾åˆ°æ ‡å‡†å•†å“å®¹å™¨ï¼Œå°†åœ¨æå–é˜¶æ®µç»§ç»­å°è¯•")
        
        logger.info(f"âœ… æœç´¢ç»“æœé¡µé¢å‡†å¤‡å®Œæˆ: {keyword}")
        return True
    
    def search_keyword(self, page: Page, keyword: str) -> bool:
        """
        æœç´¢å…³é”®è¯ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰
        
        Args:
            page: Playwright Page å¯¹è±¡
            keyword: æœç´¢å…³é”®è¯
            
        Returns:
            æ˜¯å¦æœç´¢æˆåŠŸ
        """
        try:
            # ä½¿ç”¨é‡è¯•æœºåˆ¶ï¼ˆå¢åŠ é‡è¯•æ¬¡æ•°ï¼Œå› ä¸ºç½‘ç»œå¯èƒ½ä¸ç¨³å®šï¼‰
            self.retry_with_backoff(
                self._search_keyword_internal,
                max_retries=5,  # å¢åŠ åˆ°5æ¬¡é‡è¯•
                base_delay=2.0,  # å¢åŠ åŸºç¡€å»¶è¿Ÿæ—¶é—´
                backoff_factor=1.5,  # é™ä½é€€é¿å› å­ï¼Œé¿å…ç­‰å¾…æ—¶é—´è¿‡é•¿
                page=page,
                keyword=keyword
            )
            
            # æ£€æŸ¥ Cookies æ˜¯å¦å¤±æ•ˆ
            if self.is_cookies_expired(page):
                logger.error("âŒ Cookies å·²å¤±æ•ˆï¼Œéœ€è¦é‡æ–°ç™»å½•")
                logger.error("ğŸ’¡ æç¤º: è¯·è¿è¡Œç™»å½•è®¾ç½®: python scripts/taobao_miner.py --setup-login")
                # è®°å½•å¤±æ•ˆçŠ¶æ€ï¼ˆå¯ä»¥ä¿å­˜åˆ°æ–‡ä»¶æˆ–æ•°æ®åº“ï¼‰
                return False
            
            return True
            
        except PlaywrightTimeoutError as e:
            logger.warning(f"âš ï¸ ç­‰å¾…æœç´¢ç»“æœè¶…æ—¶: {keyword} - {str(e)[:200]}")
            # æ£€æŸ¥æ˜¯å¦åœ¨ç™»å½•é¡µ
            current_url = page.url
            if 'login.taobao.com' in current_url or 'passport.taobao.com' in current_url:
                logger.error(f"âŒ è¢«é‡å®šå‘åˆ°ç™»å½•é¡µ: {current_url}")
                logger.error("ğŸ’¡ è¯·æ£€æŸ¥ç™»å½•çŠ¶æ€æˆ–é‡æ–°ç™»å½•")
                return False
            logger.info("âš ï¸ è¶…æ—¶ä½†å°†ç»§ç»­å°è¯•æå–ï¼ˆå¯èƒ½é¡µé¢å·²éƒ¨åˆ†åŠ è½½ï¼‰")
            return True  # å³ä½¿è¶…æ—¶ä¹Ÿç»§ç»­ï¼Œå¯èƒ½é¡µé¢ç»“æ„ä¸åŒ
        except Exception as e:
            error_msg = str(e)
            logger.error(f"âŒ æœç´¢å…³é”®è¯å¤±è´¥: {keyword} - {error_msg[:200]}")
            # å¦‚æœæ˜¯å…³é”®é”™è¯¯ï¼ˆåçˆ¬è™«ã€ç™»å½•ç­‰ï¼‰ï¼Œè¿”å›False
            if "è¢«åçˆ¬è™«" in error_msg or "ç™»å½•" in error_msg or "æœç´¢ç»“æœä¸ºç©º" in error_msg:
                return False
            # å…¶ä»–é”™è¯¯ï¼Œå°è¯•ç»§ç»­
            logger.warning("âš ï¸ å‡ºç°é”™è¯¯ä½†å°†ç»§ç»­å°è¯•æå–")
            return True
    
    def extract_products_from_page(self, page: Page) -> List[Dict[str, any]]:
        """
        ä»å½“å‰é¡µé¢æå–å•†å“ä¿¡æ¯
        
        Args:
            page: Playwright Page å¯¹è±¡
            
        Returns:
            å•†å“ä¿¡æ¯åˆ—è¡¨
        """
        products = []
        
        try:
            # å…ˆæ»šåŠ¨é¡µé¢ä»¥è§¦å‘æ‡’åŠ è½½ - æ›´ç§¯æçš„æ»šåŠ¨ç­–ç•¥
            logger.info("ğŸ”„ æ»šåŠ¨é¡µé¢ä»¥è§¦å‘å•†å“æ‡’åŠ è½½...")
            try:
                # æ›´é¢‘ç¹çš„åˆ†æ®µæ»šåŠ¨ï¼Œç¡®ä¿æ‰€æœ‰å•†å“éƒ½åŠ è½½
                max_scrolls = 5  # æœ€å¤šæ»šåŠ¨5æ¬¡
                last_count = 0
                stable_count = 0
                
                for scroll_round in range(max_scrolls):
                    # æ»šåŠ¨åˆ°ä¸åŒä½ç½®
                    scroll_positions = [0.2, 0.4, 0.6, 0.8, 1.0]
                    for pos in scroll_positions:
                        page.evaluate(f"window.scrollTo(0, document.body.scrollHeight * {pos})")
                        page.wait_for_timeout(800)  # å‡å°‘ç­‰å¾…æ—¶é—´
                    
                    # æ»šåŠ¨å›é¡¶éƒ¨
                    page.evaluate("window.scrollTo(0, 0)")
                    page.wait_for_timeout(500)
                    
                    # æ£€æŸ¥å½“å‰æœ‰å¤šå°‘å•†å“å…ƒç´ ï¼ˆå¿«é€Ÿæ£€æŸ¥ï¼‰
                    try:
                        quick_check = page.evaluate("""
                            () => {
                                const items = document.querySelectorAll('.items .item, .item[data-category="auctions"], [data-category="auctions"]');
                                return items.length;
                            }
                        """)
                        
                        if quick_check > last_count:
                            last_count = quick_check
                            stable_count = 0
                            logger.debug(f"ç¬¬ {scroll_round + 1} è½®æ»šåŠ¨åæ£€æµ‹åˆ° {quick_check} ä¸ªå•†å“")
                        elif quick_check == last_count and quick_check > 0:
                            stable_count += 1
                            if stable_count >= 2:  # è¿ç»­2æ¬¡æ•°é‡ä¸å˜ï¼Œè®¤ä¸ºå·²åŠ è½½å®Œæˆ
                                logger.info(f"âœ… å•†å“åŠ è½½ç¨³å®šï¼Œå…± {quick_check} ä¸ªå•†å“")
                                break
                    except:
                        pass
                    
                    if stable_count >= 2:
                        break
                    
                    # å¦‚æœå·²ç»æœ‰è¶³å¤Ÿå¤šçš„å•†å“ï¼Œå¯ä»¥æå‰ç»“æŸ
                    if last_count >= 40:
                        logger.info(f"âœ… å·²æ£€æµ‹åˆ°è¶³å¤Ÿå¤šçš„å•†å“ ({last_count} ä¸ª)ï¼Œç»§ç»­æå–")
                        break
            except Exception as e:
                logger.debug(f"æ»šåŠ¨æ“ä½œå¤±è´¥: {str(e)}")
            
            # ç›´æ¥æŸ¥è¯¢å•†å“å…ƒç´ ï¼Œä¸ç­‰å¾…é€‰æ‹©å™¨ï¼ˆæ»šåŠ¨ååº”è¯¥å·²ç»åŠ è½½ï¼‰
            logger.info("ğŸ” æŸ¥è¯¢å•†å“å…ƒç´ ...")
            
            # ä¼˜å…ˆä½¿ç”¨çš„é€‰æ‹©å™¨ï¼ˆæŒ‰å‡†ç¡®åº¦æ’åºï¼‰
            priority_selectors = [
                '.items .item',  # æœ€å‡†ç¡®
                '.items .item[data-category="auctions"]',
                '.item[data-category="auctions"]',
                '[data-category="auctions"]',
                '.m-itemlist .items .item',
            ]
            
            product_elements = None
            used_selector = None
            
            # å¿«é€Ÿå°è¯•æ¯ä¸ªé€‰æ‹©å™¨
            for selector in priority_selectors:
                try:
                    elements = page.query_selector_all(selector)
                    if elements and len(elements) > 0:
                        product_elements = elements
                        used_selector = selector
                        logger.info(f"âœ… ä½¿ç”¨é€‰æ‹©å™¨ '{selector}' æ‰¾åˆ° {len(elements)} ä¸ªå•†å“å…ƒç´ ")
                        break
                except Exception as e:
                    logger.debug(f"é€‰æ‹©å™¨ {selector} æŸ¥è¯¢å¤±è´¥: {str(e)}")
                    continue
            
            # å¦‚æœéƒ½æ²¡æ‰¾åˆ°ï¼Œå°è¯•æ›´é€šç”¨çš„æ–¹æ³•
            if not product_elements or len(product_elements) == 0:
                logger.warning("âš ï¸ æ ‡å‡†é€‰æ‹©å™¨æœªæ‰¾åˆ°å•†å“ï¼Œå°è¯•æ›´é€šç”¨çš„æ–¹æ³•...")
                try:
                    # ä½¿ç”¨JavaScriptç›´æ¥æŸ¥è¯¢ï¼Œæ›´å¿«é€Ÿ
                    element_count = page.evaluate("""
                        () => {
                            // å°è¯•å¤šç§é€‰æ‹©å™¨
                            const selectors = [
                                '.items .item',
                                '.item[data-category="auctions"]',
                                '[data-category="auctions"]',
                                '.m-itemlist .items .item',
                                '.item',
                            ];
                            
                            for (const sel of selectors) {
                                const items = document.querySelectorAll(sel);
                                if (items.length > 0) {
                                    return items.length;
                                }
                            }
                            return 0;
                        }
                    """)
                    
                    if element_count > 0:
                        # å¦‚æœæ‰¾åˆ°äº†ï¼Œä½¿ç”¨æœ€é€šç”¨çš„é€‰æ‹©å™¨è·å–
                        product_elements = page.query_selector_all('.items .item, .item[data-category="auctions"], [data-category="auctions"]')
                        used_selector = 'é€šç”¨æŸ¥è¯¢'
                        logger.info(f"âœ… ä½¿ç”¨é€šç”¨æ–¹æ³•æ‰¾åˆ° {len(product_elements)} ä¸ªå•†å“å…ƒç´ ")
                    else:
                        logger.warning("âš ï¸ é€šç”¨æ–¹æ³•ä¹Ÿæœªæ‰¾åˆ°å•†å“å…ƒç´ ")
                except Exception as e:
                    logger.debug(f"é€šç”¨æŸ¥è¯¢å¤±è´¥: {str(e)}")
            
            # æå–å•†å“å…ƒç´ ï¼ˆæ·˜å®æœç´¢ç»“æœçš„å•†å“é¡¹ï¼‰
            # product_elements åº”è¯¥å·²ç»åœ¨ä¸Šé¢è·å–åˆ°äº†
            # å¦‚æœè¿˜æ²¡æœ‰ï¼Œè¯´æ˜å‰é¢çš„é€»è¾‘æœ‰é—®é¢˜
            
            if not product_elements or len(product_elements) == 0:
                logger.error("âŒ æœªæ‰¾åˆ°å•†å“å…ƒç´ ï¼Œé¡µé¢ç»“æ„å¯èƒ½å·²å˜åŒ–æˆ–é¡µé¢æœªå®Œå…¨åŠ è½½")
                logger.info(f"å½“å‰é¡µé¢URL: {page.url}")
                logger.info(f"å½“å‰é¡µé¢æ ‡é¢˜: {page.title()}")
                
                # å°è¯•è¾“å‡ºé¡µé¢ç»“æ„ç”¨äºè°ƒè¯•
                try:
                    structure_info = page.evaluate("""
                        () => {
                            const body = document.body;
                            const itemContainers = body.querySelectorAll('[class*="item"], [data-category], [id*="item"]');
                            return {
                                total_items: itemContainers.length,
                                classes: Array.from(itemContainers).slice(0, 5).map(el => el.className)
                            };
                        }
                    """)
                    logger.debug(f"é¡µé¢ç»“æ„ä¿¡æ¯: {structure_info}")
                except:
                    pass
                
                # ä¿å­˜é¡µé¢HTMLå’Œæˆªå›¾ä»¥ä¾¿è°ƒè¯•
                try:
                    screenshot_dir = Path("scripts/screenshots")
                    screenshot_dir.mkdir(parents=True, exist_ok=True)
                    timestamp = int(time.time())
                    
                    # ä¿å­˜æˆªå›¾
                    screenshot_path = screenshot_dir / f"debug_no_products_{timestamp}.png"
                    page.screenshot(path=str(screenshot_path), full_page=True)
                    logger.info(f"ğŸ“¸ å·²ä¿å­˜è°ƒè¯•æˆªå›¾: {screenshot_path}")
                    
                    # ä¿å­˜é¡µé¢HTMLï¼ˆå‰10000å­—ç¬¦ï¼‰
                    try:
                        html_content = page.content()
                        html_path = screenshot_dir / f"debug_no_products_{timestamp}.html"
                        with open(html_path, 'w', encoding='utf-8') as f:
                            f.write(html_content[:50000])  # åªä¿å­˜å‰50KB
                        logger.info(f"å·²ä¿å­˜é¡µé¢HTML: {html_path}")
                    except Exception as e:
                        logger.debug(f"ä¿å­˜HTMLå¤±è´¥: {str(e)}")
                except Exception as e:
                    logger.debug(f"ä¿å­˜è°ƒè¯•ä¿¡æ¯å¤±è´¥: {str(e)}")
                return products
            
            logger.info(f"âœ… æ‰¾åˆ° {len(product_elements)} ä¸ªå•†å“å…ƒç´ ï¼Œå¼€å§‹æå–è¯¦ç»†ä¿¡æ¯...")
            
            # é™åˆ¶æå–æ•°é‡ï¼Œé¿å…è¿‡å¤šï¼ˆæ¯é¡µé€šå¸¸48ä¸ªå•†å“ï¼‰
            max_extract = min(len(product_elements), 48)
            if len(product_elements) > max_extract:
                logger.info(f"ğŸ“Š å•†å“æ•°é‡è¾ƒå¤šï¼ˆ{len(product_elements)}ï¼‰ï¼Œå°†æå–å‰ {max_extract} ä¸ª")
            product_elements = product_elements[:max_extract]
            
            logger.info(f"ğŸ“¦ å‡†å¤‡æå– {len(product_elements)} ä¸ªå•†å“çš„è¯¦ç»†ä¿¡æ¯...")
            
            extracted_count = 0
            for idx, item in enumerate(product_elements, 1):
                if idx % 10 == 0:
                    logger.info(f"ğŸ“Š æå–è¿›åº¦: {idx}/{len(product_elements)} ({extracted_count} ä¸ªæˆåŠŸ)")
                try:
                    product_info = {}
                    
                    # æå–æ ‡é¢˜ - æ‰©å±•æ›´å¤šé€‰æ‹©å™¨
                    title_selectors = [
                        '.title a',  # æ ‡é¢˜é“¾æ¥
                        '.title',  # æ ‡é¢˜å®¹å™¨
                        'a[title]',  # å¸¦titleå±æ€§çš„é“¾æ¥
                        '.J_ClickStat',  # ç‚¹å‡»ç»Ÿè®¡å…ƒç´ 
                        'a.J_ClickStat',  # ç‚¹å‡»ç»Ÿè®¡é“¾æ¥
                        '.item-title',  # å•†å“æ ‡é¢˜ç±»
                        '.item-title a',  # å•†å“æ ‡é¢˜é“¾æ¥
                        '[class*="title"] a',  # åŒ…å«titleçš„ç±»çš„é“¾æ¥
                        '[class*="Title"] a',  # åŒ…å«Titleçš„ç±»çš„é“¾æ¥
                        'a[href*="item"]',  # å•†å“é“¾æ¥
                        '.pic-link',  # å›¾ç‰‡é“¾æ¥ï¼ˆé€šå¸¸åŒ…å«titleï¼‰
                        'a.pic-link',  # å›¾ç‰‡é“¾æ¥
                    ]
                    
                    title = None
                    title_link = None
                    title_extraction_method = None
                    
                    # æ–¹æ³•1: ä½¿ç”¨æ ‡å‡†é€‰æ‹©å™¨
                    for title_sel in title_selectors:
                        try:
                            title_elem = item.query_selector(title_sel)
                            if title_elem:
                                # å°è¯•å¤šç§æ–¹å¼è·å–æ ‡é¢˜
                                title = title_elem.get_attribute('title')
                                if not title:
                                    title = title_elem.get_attribute('alt')  # å›¾ç‰‡altå±æ€§
                                if not title:
                                    title = title_elem.inner_text().strip()
                                
                                if title and len(title) > 5:  # æ ‡é¢˜åº”è¯¥æœ‰ä¸€å®šé•¿åº¦
                                    title_link = title_elem.get_attribute('href')
                                    title_extraction_method = f"é€‰æ‹©å™¨: {title_sel}"
                                    break
                        except Exception as e:
                            logger.debug(f"æ ‡é¢˜é€‰æ‹©å™¨ {title_sel} å¤±è´¥: {str(e)}")
                            continue
                    
                    # æ–¹æ³•2: å¦‚æœæ ‡å‡†é€‰æ‹©å™¨å¤±è´¥ï¼Œå°è¯•æŸ¥æ‰¾å…ƒç´ å†…çš„æ‰€æœ‰é“¾æ¥
                    if not title:
                        try:
                            # æŸ¥æ‰¾å…ƒç´ å†…æ‰€æœ‰é“¾æ¥
                            all_links = item.query_selector_all('a')
                            for link in all_links:
                                try:
                                    # æ£€æŸ¥é“¾æ¥æ˜¯å¦æŒ‡å‘å•†å“è¯¦æƒ…é¡µ
                                    href = link.get_attribute('href') or ''
                                    if 'item.taobao.com' in href or 'detail.tmall.com' in href or '/item/' in href:
                                        # å°è¯•ä»é“¾æ¥è·å–æ ‡é¢˜
                                        link_title = link.get_attribute('title')
                                        if not link_title:
                                            link_title = link.inner_text().strip()
                                        if link_title and len(link_title) > 5:
                                            title = link_title
                                            title_link = href
                                            title_extraction_method = "ä»å•†å“é“¾æ¥æå–"
                                            break
                                except:
                                    continue
                        except Exception as e:
                            logger.debug(f"ä»é“¾æ¥æå–æ ‡é¢˜å¤±è´¥: {str(e)}")
                    
                    # æ–¹æ³•3: å¦‚æœè¿˜æ˜¯å¤±è´¥ï¼Œå°è¯•ä»å…ƒç´ æœ¬èº«æå–æ–‡æœ¬
                    if not title:
                        try:
                            # è·å–å…ƒç´ çš„æ‰€æœ‰æ–‡æœ¬å†…å®¹
                            all_text = item.inner_text().strip()
                            if all_text:
                                # å°è¯•æå–æœ€é•¿çš„æ–‡æœ¬è¡Œä½œä¸ºæ ‡é¢˜
                                lines = [line.strip() for line in all_text.split('\n') if line.strip()]
                                if lines:
                                    # æ‰¾åˆ°æœ€é•¿çš„è¡Œï¼ˆé€šå¸¸æ˜¯æ ‡é¢˜ï¼‰
                                    longest_line = max(lines, key=len)
                                    if len(longest_line) > 5:
                                        title = longest_line
                                        title_extraction_method = "ä»å…ƒç´ æ–‡æœ¬æå–"
                                        
                                        # å°è¯•æ‰¾åˆ°å¯¹åº”çš„é“¾æ¥
                                        try:
                                            link_in_item = item.query_selector('a[href*="item"]')
                                            if link_in_item:
                                                title_link = link_in_item.get_attribute('href')
                                        except:
                                            pass
                        except Exception as e:
                            logger.debug(f"ä»å…ƒç´ æ–‡æœ¬æå–æ ‡é¢˜å¤±è´¥: {str(e)}")
                    
                    if not title:
                        # è¾“å‡ºè¯¦ç»†çš„è°ƒè¯•ä¿¡æ¯ï¼ˆåªåœ¨debugæ¨¡å¼ä¸‹ï¼‰
                        if logger.level <= 10:  # DEBUG level
                            try:
                                item_html = item.inner_html()[:200]  # å‰200å­—ç¬¦
                                logger.debug(f"å•†å“ {idx} æœªæ‰¾åˆ°æ ‡é¢˜ï¼ŒHTMLé¢„è§ˆ: {item_html}...")
                            except:
                                pass
                        continue
                    
                    if idx <= 3 or idx % 10 == 0:  # å‰3ä¸ªå’Œæ¯10ä¸ªè¾“å‡ºè¯¦ç»†æ—¥å¿—
                        logger.debug(f"å•†å“ {idx} æ ‡é¢˜æå–æˆåŠŸ ({title_extraction_method}): {title[:50]}...")
                    
                    product_info['title'] = title.strip()
                    
                    # å¤„ç†é“¾æ¥ï¼ˆå¦‚æœæ˜¯ç›¸å¯¹è·¯å¾„ï¼Œè¡¥å…¨ä¸ºå®Œæ•´URLï¼‰
                    if title_link:
                        if title_link.startswith('//'):
                            title_link = 'https:' + title_link
                        elif title_link.startswith('/'):
                            title_link = 'https://www.taobao.com' + title_link
                        product_info['detail_url'] = title_link
                    else:
                        product_info['detail_url'] = None
                    
                    # æå–ä»·æ ¼ - æ‰©å±•æ›´å¤šé€‰æ‹©å™¨
                    price_selectors = [
                        '.price strong',  # ä»·æ ¼å¼ºæ ‡ç­¾
                        '.price',  # ä»·æ ¼å®¹å™¨
                        '.price .price-num',  # ä»·æ ¼æ•°å­—
                        '.item-price',  # å•†å“ä»·æ ¼ç±»
                        '[class*="price"]',  # åŒ…å«priceçš„ç±»
                        '[class*="Price"]',  # åŒ…å«Priceçš„ç±»
                        '.g-price',  # g-å¼€å¤´çš„ä»·æ ¼ç±»
                        '.price-box',  # ä»·æ ¼ç›’å­
                    ]
                    
                    price = None
                    for price_sel in price_selectors:
                        try:
                            price_elem = item.query_selector(price_sel)
                            if price_elem:
                                price_text = price_elem.inner_text().strip()
                                # æå–æ•°å­—éƒ¨åˆ†ï¼ˆæ”¯æŒå°æ•°ç‚¹ï¼‰
                                price_match = re.search(r'(\d+\.?\d*)', price_text.replace(',', '').replace('ï¿¥', '').replace('Â¥', ''))
                                if price_match:
                                    price_val = float(price_match.group(1))
                                    # ä»·æ ¼åº”è¯¥åˆç†ï¼ˆ1-100000ä¹‹é—´ï¼‰
                                    if 1 <= price_val <= 100000:
                                        price = price_val
                                        break
                        except Exception as e:
                            logger.debug(f"ä»·æ ¼é€‰æ‹©å™¨ {price_sel} å¤±è´¥: {str(e)}")
                            continue
                    
                    # å¦‚æœæ ‡å‡†é€‰æ‹©å™¨å¤±è´¥ï¼Œå°è¯•ä»å…ƒç´ æ–‡æœ¬ä¸­æå–ä»·æ ¼
                    if price is None:
                        try:
                            all_text = item.inner_text()
                            # æŸ¥æ‰¾åŒ…å«"ï¿¥"æˆ–"Â¥"çš„æ–‡æœ¬
                            price_patterns = [
                                r'[ï¿¥Â¥]\s*(\d+\.?\d*)',  # ï¿¥123.45
                                r'(\d+\.?\d*)\s*å…ƒ',  # 123.45å…ƒ
                                r'ä»·æ ¼[ï¼š:]\s*(\d+\.?\d*)',  # ä»·æ ¼ï¼š123.45
                            ]
                            for pattern in price_patterns:
                                match = re.search(pattern, all_text)
                                if match:
                                    price_val = float(match.group(1))
                                    if 1 <= price_val <= 100000:
                                        price = price_val
                                        break
                        except:
                            pass
                    
                    product_info['price'] = price
                    
                    # æå–é”€é‡ - æ‰©å±•æ›´å¤šé€‰æ‹©å™¨å’Œæ¨¡å¼
                    sales_selectors = [
                        '.deal-cnt',  # æˆäº¤æ•°
                        '.sales',  # é”€é‡
                        '[class*="deal"]',  # åŒ…å«dealçš„ç±»
                        '[class*="Deal"]',  # åŒ…å«Dealçš„ç±»
                        '.item-sales',  # å•†å“é”€é‡ç±»
                        '[class*="sales"]',  # åŒ…å«salesçš„ç±»
                        '[class*="Sales"]',  # åŒ…å«Salesçš„ç±»
                    ]
                    
                    sales = None
                    for sales_sel in sales_selectors:
                        try:
                            sales_elem = item.query_selector(sales_sel)
                            if sales_elem:
                                sales_text = sales_elem.inner_text().strip()
                                # æå–æ•°å­—ï¼Œå¤„ç†"æœˆé”€100+"ã€"100+"ã€"1.5ä¸‡+"ç­‰æ ¼å¼
                                sales_text = sales_text.replace('æœˆé”€', '').replace('äººä»˜æ¬¾', '').replace('+', '').strip()
                                
                                # å¤„ç†"ä¸‡"å•ä½
                                if 'ä¸‡' in sales_text:
                                    num_match = re.search(r'(\d+\.?\d*)', sales_text)
                                    if num_match:
                                        sales = int(float(num_match.group(1)) * 10000)
                                else:
                                    num_match = re.search(r'(\d+)', sales_text.replace(',', ''))
                                    if num_match:
                                        sales = int(num_match.group(1))
                                if sales:
                                    break
                        except Exception as e:
                            logger.debug(f"é”€é‡é€‰æ‹©å™¨ {sales_sel} å¤±è´¥: {str(e)}")
                            continue
                    
                    # å¦‚æœæ ‡å‡†é€‰æ‹©å™¨å¤±è´¥ï¼Œå°è¯•ä»å…ƒç´ æ–‡æœ¬ä¸­æå–é”€é‡
                    if sales is None:
                        try:
                            all_text = item.inner_text()
                            # æŸ¥æ‰¾åŒ…å«é”€é‡å…³é”®è¯çš„æ–‡æœ¬
                            sales_patterns = [
                                r'æœˆé”€[ï¼š:]?\s*(\d+)',  # æœˆé”€1000
                                r'å·²å”®[ï¼š:]?\s*(\d+)',  # å·²å”®1000
                                r'(\d+)\s*äººä»˜æ¬¾',  # 1000äººä»˜æ¬¾
                                r'é”€é‡[ï¼š:]?\s*(\d+)',  # é”€é‡1000
                                r'æˆäº¤[ï¼š:]?\s*(\d+)',  # æˆäº¤1000
                            ]
                            for pattern in sales_patterns:
                                match = re.search(pattern, all_text)
                                if match:
                                    sales = int(match.group(1))
                                    break
                        except:
                            pass
                    
                    product_info['sales'] = sales
                    
                    # æå–åº—é“ºå
                    shop_selectors = [
                        '.shop a',  # åº—é“ºé“¾æ¥
                        '.shop',  # åº—é“ºå®¹å™¨
                        '.nick',  # åº—é“ºæ˜µç§°
                    ]
                    
                    shop_name = None
                    for shop_sel in shop_selectors:
                        try:
                            shop_elem = item.query_selector(shop_sel)
                            if shop_elem:
                                shop_name = shop_elem.inner_text().strip()
                                if shop_name:
                                    break
                        except:
                            continue
                    
                    product_info['shop_name'] = shop_name
                    
                    # æå–åº—é“ºç±»å‹ï¼ˆCåº—/å¤©çŒ«ï¼‰
                    shop_type = None
                    try:
                        # æ£€æŸ¥å•†å“é“¾æ¥æˆ–åº—é“ºé“¾æ¥æ˜¯å¦åŒ…å« tmall
                        detail_url = product_info.get('detail_url', '')
                        if detail_url:
                            if 'tmall.com' in detail_url or 'detail.tmall' in detail_url:
                                shop_type = 'tmall'
                            elif 'taobao.com' in detail_url:
                                shop_type = 'c_shop'
                        
                        # ä¹Ÿå¯ä»¥é€šè¿‡é¡µé¢å…ƒç´ åˆ¤æ–­
                        if not shop_type:
                            shop_badge = item.query_selector('.shop-badge, .shop-type, [class*="tmall"]')
                            if shop_badge:
                                badge_text = shop_badge.inner_text().strip().lower()
                                if 'å¤©çŒ«' in badge_text or 'tmall' in badge_text:
                                    shop_type = 'tmall'
                                else:
                                    shop_type = 'c_shop'
                        
                        product_info['shop_type'] = shop_type
                    except:
                        product_info['shop_type'] = None
                    
                    # åªæ·»åŠ æœ‰æ ‡é¢˜çš„å•†å“ï¼ˆåŸºæœ¬è¦æ±‚ï¼‰
                    if product_info.get('title'):
                        products.append(product_info)
                        extracted_count += 1
                        # åªè¾“å‡ºå‰5ä¸ªå’Œæ¯10ä¸ªï¼Œå‡å°‘æ—¥å¿—é‡
                        if idx <= 5 or (idx % 10 == 0):
                            logger.info(f"âœ… [{idx}/{len(product_elements)}] {product_info['title'][:40]}... | Â¥{price or 'N/A'} | é”€é‡:{sales or 'N/A'}")
                    else:
                        if idx <= 3:  # åªè¾“å‡ºå‰3ä¸ªå¤±è´¥çš„
                            logger.debug(f"âŒ å•†å“ {idx} æœªæå–åˆ°æ ‡é¢˜ï¼Œè·³è¿‡")
                    
                except Exception as e:
                    logger.warning(f"æå–å•†å“ {idx} ä¿¡æ¯æ—¶å‡ºé”™: {str(e)}")
                    # è¾“å‡ºå…ƒç´ çš„åŸºæœ¬ä¿¡æ¯ç”¨äºè°ƒè¯•
                    try:
                        item_class = item.get_attribute('class') or 'N/A'
                        logger.debug(f"å¤±è´¥å…ƒç´ çš„class: {item_class[:100]}")
                    except:
                        pass
                    continue
            
            logger.info(f"âœ… æˆåŠŸæå– {len(products)} ä¸ªå•†å“ä¿¡æ¯ (ä» {len(product_elements)} ä¸ªå…ƒç´ ä¸­)")
            if len(products) == 0 and len(product_elements) > 0:
                logger.warning(f"âš ï¸ è­¦å‘Š: æ‰¾åˆ°äº† {len(product_elements)} ä¸ªå•†å“å…ƒç´ ï¼Œä½†æå–å¤±è´¥ã€‚å¯èƒ½éœ€è¦æ£€æŸ¥é¡µé¢ç»“æ„ã€‚")
                # è¾“å‡ºç¬¬ä¸€ä¸ªå…ƒç´ çš„HTMLç”¨äºè°ƒè¯•
                try:
                    first_elem_html = product_elements[0].inner_html()[:500]
                    logger.debug(f"ç¬¬ä¸€ä¸ªå…ƒç´ çš„HTMLé¢„è§ˆ: {first_elem_html}...")
                except:
                    pass
            
        except Exception as e:
            logger.error(f"æå–å•†å“ä¿¡æ¯æ—¶å‡ºé”™: {str(e)}")
        
        return products
    
    def go_to_next_page(self, page: Page) -> bool:
        """
        ç¿»åˆ°ä¸‹ä¸€é¡µ
        
        Args:
            page: Playwright Page å¯¹è±¡
            
        Returns:
            æ˜¯å¦æˆåŠŸç¿»é¡µ
        """
        try:
            # æŸ¥æ‰¾"ä¸‹ä¸€é¡µ"æŒ‰é’®
            next_page_selectors = [
                '.next:not(.disabled)',  # ä¸‹ä¸€é¡µæŒ‰é’®ï¼ˆæœªç¦ç”¨ï¼‰
                'a[aria-label="ä¸‹ä¸€é¡µ"]',  # æ— éšœç¢æ ‡ç­¾
                '.pagination .next',
                '.page-next:not(.disabled)',
            ]
            
            next_button = None
            for selector in next_page_selectors:
                try:
                    next_button = page.query_selector(selector)
                    if next_button and next_button.is_visible():
                        break
                except:
                    continue
            
            if not next_button:
                logger.debug("æœªæ‰¾åˆ°ä¸‹ä¸€é¡µæŒ‰é’®ï¼Œå¯èƒ½å·²åˆ°æœ€åä¸€é¡µ")
                return False
            
            # æ£€æŸ¥æ˜¯å¦è¢«ç¦ç”¨
            try:
                if 'disabled' in next_button.get_attribute('class') or '':
                    logger.debug("ä¸‹ä¸€é¡µæŒ‰é’®å·²ç¦ç”¨ï¼Œå·²åˆ°æœ€åä¸€é¡µ")
                    return False
            except:
                pass
            
            # ç‚¹å‡»ä¸‹ä¸€é¡µ
            next_button.click()
            
            # ç­‰å¾…é¡µé¢åŠ è½½ï¼ˆå¢åŠ ç­‰å¾…æ—¶é—´ï¼‰
            self.wait_random(2.0, 3.0)
            try:
                page.wait_for_load_state('networkidle', timeout=20000)
            except PlaywrightTimeoutError:
                logger.warning("ç¿»é¡µåç½‘ç»œæœªå®Œå…¨ç©ºé—²ï¼Œç»§ç»­ç­‰å¾…...")
                page.wait_for_timeout(3000)
            
            # éªŒè¯æ˜¯å¦æˆåŠŸç¿»é¡µï¼ˆç­‰å¾…æ–°å•†å“åŠ è½½ï¼Œä½¿ç”¨å¤šä¸ªé€‰æ‹©å™¨ï¼‰
            possible_selectors = [
                '.items .item',
                '.items .item[data-category="auctions"]',
                '[data-category="auctions"]',
            ]
            
            for selector in possible_selectors:
                try:
                    page.wait_for_selector(selector, timeout=15000, state='visible')
                    logger.debug(f"æˆåŠŸç¿»åˆ°ä¸‹ä¸€é¡µï¼Œæ‰¾åˆ°å…ƒç´ : {selector}")
                    return True
                except PlaywrightTimeoutError:
                    continue
            
            logger.warning("ç¿»é¡µåç­‰å¾…å•†å“åŠ è½½è¶…æ—¶ï¼Œä½†ç»§ç»­å°è¯•æå–")
            return True  # å³ä½¿è¶…æ—¶ä¹Ÿè®¤ä¸ºæˆåŠŸï¼Œå¯èƒ½åœ¨ extract ä¸­èƒ½æ‰¾åˆ°
            
        except Exception as e:
            logger.error(f"ç¿»é¡µå¤±è´¥: {str(e)}")
            return False
    
    def mine_keywords(self, seed_words: List[str], max_pages: int = 5, 
                     min_sales: int = 50, max_sales: int = 5000, 
                     apply_sales_filter: bool = False) -> List[Dict[str, any]]:
        """
        æŒ–æ˜å…³é”®è¯ï¼ˆæ ¸å¿ƒæŠ“å–é€»è¾‘ï¼‰
        
        Args:
            seed_words: ç§å­è¯åˆ—è¡¨ï¼Œä¾‹å¦‚ ["é‡ç”Ÿ", "è‡ªåˆ¶"]
            max_pages: æ¯ä¸ªç§å­è¯æœ€å¤šæŠ“å–é¡µæ•°ï¼ˆé»˜è®¤5é¡µï¼‰
            min_sales: æœ€å°é”€é‡è¿‡æ»¤ï¼ˆé»˜è®¤50ï¼‰
            max_sales: æœ€å¤§é”€é‡è¿‡æ»¤ï¼ˆé»˜è®¤5000ï¼‰
            
        Returns:
            æ‰€æœ‰æŠ“å–åˆ°çš„å•†å“åˆ—è¡¨
        """
        all_products = []
        
        logger.info("=" * 60)
        logger.info("å¼€å§‹æ·˜å®å…³é”®è¯æŒ–æ˜")
        logger.info(f"ç§å­è¯: {', '.join(seed_words)}")
        logger.info(f"æ¯ä¸ªè¯æŠ“å–é¡µæ•°: {max_pages}")
        logger.info(f"é”€é‡è¿‡æ»¤èŒƒå›´: {min_sales} - {max_sales}")
        logger.info("=" * 60)
        
        with sync_playwright() as p:
            browser, context, page = self.create_browser_context(p)
            
            try:
                # éªŒè¯ç™»å½•çŠ¶æ€
                if not self.is_logged_in(page):
                    logger.error("âŒ æœªç™»å½•ï¼Œè¯·å…ˆè¿è¡Œç™»å½•è®¾ç½®: python taobao_miner.py")
                    browser.close()
                    return all_products
                
                logger.info("âœ… ç™»å½•çŠ¶æ€éªŒè¯é€šè¿‡")
                
                # éå†æ¯ä¸ªç§å­è¯
                for seed_idx, seed_word in enumerate(seed_words, 1):
                    logger.info("=" * 60)
                    logger.info(f"[{seed_idx}/{len(seed_words)}] å¤„ç†ç§å­è¯: {seed_word}")
                    logger.info("=" * 60)
                    
                    # æœç´¢å…³é”®è¯
                    logger.info(f"ğŸ” å¼€å§‹æœç´¢å…³é”®è¯: {seed_word}")
                    search_success = self.search_keyword(page, seed_word)
                    
                    if not search_success:
                        logger.warning(f"âš ï¸ æœç´¢å¯èƒ½å¤±è´¥ï¼Œä½†å°†ç»§ç»­å°è¯•æå–ç§å­è¯: {seed_word}")
                        # ä¸ç›´æ¥è·³è¿‡ï¼Œå°è¯•æå–å½“å‰é¡µé¢ï¼ˆå¯èƒ½éƒ¨åˆ†åŠ è½½æˆåŠŸï¼‰
                    
                    # éå†æ¯ä¸€é¡µ
                    for page_num in range(1, max_pages + 1):
                        logger.info("")
                        logger.info(f"{'='*60}")
                        logger.info(f"--- ç¬¬ {page_num} é¡µ ---")
                        logger.info(f"{'='*60}")
                        
                        # æå–å½“å‰é¡µå•†å“
                        logger.info(f"ğŸ“¦ å¼€å§‹æå–ç¬¬ {page_num} é¡µå•†å“...")
                        try:
                            products = self.extract_products_from_page(page)
                            logger.info(f"âœ… ç¬¬ {page_num} é¡µæå–å®Œæˆï¼Œè·å¾— {len(products)} ä¸ªå•†å“")
                        except Exception as e:
                            logger.error(f"âŒ æå–ç¬¬ {page_num} é¡µå•†å“æ—¶å‡ºé”™: {str(e)[:200]}")
                            products = []  # ç©ºåˆ—è¡¨ï¼Œç»§ç»­ä¸‹ä¸€é¡µ
                        
                        # æ·»åŠ ç§å­è¯ä¿¡æ¯åˆ°å•†å“æ•°æ®
                        for product in products:
                            product['seed_word'] = seed_word
                            product['page_num'] = page_num
                        
                        # å¦‚æœå¯ç”¨é”€é‡è¿‡æ»¤ï¼Œåœ¨è¿™é‡Œå…ˆè¿‡æ»¤ï¼ˆä½†é€šå¸¸åœ¨å¤–å±‚ç»Ÿä¸€è¿‡æ»¤æ›´å¥½ï¼‰
                        if apply_sales_filter:
                            products = self.filter_products_by_sales(products, min_sales, max_sales)
                        
                        all_products.extend(products)
                        logger.info(f"å½“å‰é¡µæå– {len(products)} ä¸ªå•†å“ï¼Œç´¯è®¡ {len(all_products)} ä¸ª")
                        
                        # å¦‚æœä¸æ˜¯æœ€åä¸€é¡µï¼Œå°è¯•ç¿»é¡µ
                        if page_num < max_pages:
                            # éšæœºç­‰å¾…å†ç¿»é¡µ
                            self.wait_random(2.0, 4.0)
                            
                            if not self.go_to_next_page(page):
                                logger.info(f"æ— æ³•ç¿»é¡µï¼Œåœæ­¢æŠ“å–ç§å­è¯: {seed_word}")
                                break
                        else:
                            logger.info(f"å·²å®Œæˆ {max_pages} é¡µæŠ“å–ï¼Œç»§ç»­ä¸‹ä¸€ä¸ªç§å­è¯")
                    
                    # æ¯ä¸ªç§å­è¯ä¹‹é—´ç­‰å¾…
                    if seed_idx < len(seed_words):
                        logger.info("ç­‰å¾…åå¤„ç†ä¸‹ä¸€ä¸ªç§å­è¯...")
                        self.wait_random(3.0, 5.0)
                
                logger.info("=" * 60)
                logger.info(f"âœ… æŠ“å–å®Œæˆï¼å…±è·å– {len(all_products)} ä¸ªå•†å“")
                logger.info("=" * 60)
                
            except KeyboardInterrupt:
                logger.info("\nç”¨æˆ·ä¸­æ–­æŠ“å–")
            except Exception as e:
                logger.error(f"æŠ“å–è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}", exc_info=True)
            finally:
                browser.close()
        
        return all_products
    
    def filter_products_by_sales(self, products: List[Dict[str, any]], 
                                  min_sales: int, max_sales: int) -> List[Dict[str, any]]:
        """
        æŒ‰é”€é‡è¿‡æ»¤å•†å“
        
        Args:
            products: å•†å“åˆ—è¡¨
            min_sales: æœ€å°é”€é‡
            max_sales: æœ€å¤§é”€é‡
            
        Returns:
            è¿‡æ»¤åçš„å•†å“åˆ—è¡¨
        """
        filtered = []
        for product in products:
            sales = product.get('sales')
            if sales is None:
                continue
            if min_sales <= sales <= max_sales:
                filtered.append(product)
        return filtered
    
    def filter_products_by_price(self, products: List[Dict[str, any]], 
                                 min_price: Optional[float] = None, 
                                 max_price: Optional[float] = None) -> List[Dict[str, any]]:
        """
        æŒ‰ä»·æ ¼è¿‡æ»¤å•†å“
        
        Args:
            products: å•†å“åˆ—è¡¨
            min_price: æœ€å°ä»·æ ¼ï¼ˆå¯é€‰ï¼‰
            max_price: æœ€å¤§ä»·æ ¼ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            è¿‡æ»¤åçš„å•†å“åˆ—è¡¨
        """
        if min_price is None and max_price is None:
            return products  # æ²¡æœ‰ä»·æ ¼ç­›é€‰æ¡ä»¶ï¼Œè¿”å›å…¨éƒ¨
        
        filtered = []
        for product in products:
            price = product.get('price')
            if price is None:
                continue
            
            # æ£€æŸ¥ä»·æ ¼èŒƒå›´
            if min_price is not None and price < min_price:
                continue
            if max_price is not None and price > max_price:
                continue
            
            filtered.append(product)
        return filtered
    
    def filter_products_by_keywords(self, products: List[Dict[str, any]],
                                   must_contain: Optional[List[str]] = None,
                                   must_not_contain: Optional[List[str]] = None) -> List[Dict[str, any]]:
        """
        æŒ‰å…³é”®è¯è¿‡æ»¤å•†å“ï¼ˆå¿…é¡»åŒ…å«/ä¸èƒ½åŒ…å«ï¼‰
        
        Args:
            products: å•†å“åˆ—è¡¨
            must_contain: å¿…é¡»åŒ…å«çš„å…³é”®è¯åˆ—è¡¨ï¼ˆAND å…³ç³»ï¼Œæ‰€æœ‰å…³é”®è¯éƒ½è¦åŒ…å«ï¼‰
            must_not_contain: ä¸èƒ½åŒ…å«çš„å…³é”®è¯åˆ—è¡¨ï¼ˆOR å…³ç³»ï¼ŒåŒ…å«ä»»æ„ä¸€ä¸ªå°±æ’é™¤ï¼‰
            
        Returns:
            è¿‡æ»¤åçš„å•†å“åˆ—è¡¨
        """
        if not must_contain and not must_not_contain:
            return products  # æ²¡æœ‰å…³é”®è¯ç­›é€‰æ¡ä»¶ï¼Œè¿”å›å…¨éƒ¨
        
        filtered = []
        for product in products:
            title = product.get('title', '').lower()
            
            # å¿…é¡»åŒ…å«ï¼šæ‰€æœ‰å…³é”®è¯éƒ½è¦åŒ…å«ï¼ˆAND å…³ç³»ï¼‰
            if must_contain:
                all_contained = True
                for keyword in must_contain:
                    if keyword.lower() not in title:
                        all_contained = False
                        break
                if not all_contained:
                    continue
            
            # ä¸èƒ½åŒ…å«ï¼šåŒ…å«ä»»æ„ä¸€ä¸ªå°±æ’é™¤ï¼ˆOR å…³ç³»ï¼‰
            if must_not_contain:
                should_exclude = False
                for keyword in must_not_contain:
                    if keyword.lower() in title:
                        should_exclude = True
                        break
                if should_exclude:
                    continue
            
            filtered.append(product)
        return filtered
    
    def filter_products_by_shop_type(self, products: List[Dict[str, any]],
                                    shop_type: Optional[str] = None) -> List[Dict[str, any]]:
        """
        æŒ‰åº—é“ºç±»å‹è¿‡æ»¤å•†å“
        
        Args:
            products: å•†å“åˆ—è¡¨
            shop_type: åº—é“ºç±»å‹ ('tmall'/'c_shop'/None)ï¼ŒNone è¡¨ç¤ºä¸é™
            
        Returns:
            è¿‡æ»¤åçš„å•†å“åˆ—è¡¨
        """
        if shop_type is None or shop_type == 'all':
            return products  # ä¸é™åº—é“ºç±»å‹ï¼Œè¿”å›å…¨éƒ¨
        
        filtered = []
        for product in products:
            product_shop_type = product.get('shop_type')
            if shop_type == 'tmall' and product_shop_type == 'tmall':
                filtered.append(product)
            elif shop_type == 'c_shop' and product_shop_type == 'c_shop':
                filtered.append(product)
            elif shop_type == 'c_shop' and product_shop_type is None:
                # å¦‚æœæ— æ³•è¯†åˆ«åº—é“ºç±»å‹ï¼Œé»˜è®¤å½“ä½œ Cåº— å¤„ç†
                filtered.append(product)
        
        return filtered
    
    def clean_title_as_keyword(self, title: str) -> str:
        """
        æ¸…æ´—å•†å“æ ‡é¢˜ï¼Œæå–ä¸ºå…³é”®è¯
        
        Args:
            title: å•†å“æ ‡é¢˜
            
        Returns:
            æ¸…æ´—åçš„å…³é”®è¯
        """
        if not title:
            return ""
        
        # ç§»é™¤å¸¸è§çš„æ ‡ç‚¹ç¬¦å·å’Œç‰¹æ®Šå­—ç¬¦
        # ä¿ç•™ä¸­æ–‡ã€è‹±æ–‡ã€æ•°å­—å’ŒåŸºæœ¬æ ‡ç‚¹
        import re
        # ç§»é™¤ç‰¹æ®Šå­—ç¬¦ï¼Œä½†ä¿ç•™ä¸­æ–‡ã€è‹±æ–‡ã€æ•°å­—ã€ç©ºæ ¼
        cleaned = re.sub(r'[^\u4e00-\u9fa5a-zA-Z0-9\s]', ' ', title)
        # ç§»é™¤å¤šä½™ç©ºæ ¼
        cleaned = re.sub(r'\s+', ' ', cleaned).strip()
        
        return cleaned
    
    def mine_and_save(self, seed_words: List[str], project_id: str, 
                     max_pages: int = 5, min_sales: int = 50, 
                     max_sales: int = 5000,
                     min_price: Optional[float] = None,
                     max_price: Optional[float] = None,
                     must_contain_keywords: Optional[List[str]] = None,
                     must_not_contain_keywords: Optional[List[str]] = None,
                     shop_type: Optional[str] = None) -> Dict[str, int]:
        """
        æŒ–æ˜å…³é”®è¯å¹¶ä¿å­˜åˆ°æ•°æ®åº“
        
        Args:
            seed_words: ç§å­è¯åˆ—è¡¨
            project_id: é¡¹ç›®ID
            max_pages: æ¯ä¸ªç§å­è¯æœ€å¤šæŠ“å–é¡µæ•°
            min_sales: æœ€å°é”€é‡
            max_sales: æœ€å¤§é”€é‡
            min_price: æœ€å°ä»·æ ¼ï¼ˆå¯é€‰ï¼‰
            max_price: æœ€å¤§ä»·æ ¼ï¼ˆå¯é€‰ï¼‰
            must_contain_keywords: å¿…é¡»åŒ…å«çš„å…³é”®è¯åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰
            must_not_contain_keywords: ä¸èƒ½åŒ…å«çš„å…³é”®è¯åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰
            shop_type: åº—é“ºç±»å‹ ('tmall'/'c_shop'/Noneï¼ŒNoneè¡¨ç¤ºä¸é™)
            
        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        if not self.supabase:
            logger.error("âŒ Supabase å®¢æˆ·ç«¯æœªåˆå§‹åŒ–ï¼Œæ— æ³•ä¿å­˜æ•°æ®")
            return {'total_crawled': 0, 'after_sales_filter': 0, 'after_price_filter': 0, 
                   'after_keyword_filter': 0, 'after_shop_type_filter': 0, 'inserted': 0}
        
        # æŠ“å–å•†å“
        all_products = self.mine_keywords(
            seed_words=seed_words,
            max_pages=max_pages,
            min_sales=min_sales,
            max_sales=max_sales,
            apply_sales_filter=False  # ç»Ÿä¸€åœ¨å¤–å±‚è¿‡æ»¤
        )
        
        total_crawled = len(all_products)
        logger.info(f"ğŸ“Š æŠ“å–å®Œæˆï¼Œå…± {total_crawled} ä¸ªå•†å“")
        
        # æŒ‰é”€é‡è¿‡æ»¤
        filtered_products = self.filter_products_by_sales(all_products, min_sales, max_sales)
        after_sales_filter = len(filtered_products)
        logger.info(f"ğŸ“Š é”€é‡è¿‡æ»¤å: {after_sales_filter} ä¸ªå•†å“")
        
        # æŒ‰ä»·æ ¼è¿‡æ»¤
        if min_price is not None or max_price is not None:
            filtered_products = self.filter_products_by_price(
                filtered_products, min_price, max_price
            )
        after_price_filter = len(filtered_products)
        if min_price is not None or max_price is not None:
            logger.info(f"ğŸ“Š ä»·æ ¼è¿‡æ»¤å: {after_price_filter} ä¸ªå•†å“")
        
        # æŒ‰å…³é”®è¯è¿‡æ»¤
        if must_contain_keywords or must_not_contain_keywords:
            filtered_products = self.filter_products_by_keywords(
                filtered_products,
                must_contain=must_contain_keywords,
                must_not_contain=must_not_contain_keywords
            )
        after_keyword_filter = len(filtered_products)
        if must_contain_keywords or must_not_contain_keywords:
            logger.info(f"ğŸ“Š å…³é”®è¯è¿‡æ»¤å: {after_keyword_filter} ä¸ªå•†å“")
        
        # æŒ‰åº—é“ºç±»å‹è¿‡æ»¤
        if shop_type:
            filtered_products = self.filter_products_by_shop_type(
                filtered_products, shop_type
            )
        after_shop_type_filter = len(filtered_products)
        if shop_type:
            logger.info(f"ğŸ“Š åº—é“ºç±»å‹è¿‡æ»¤å: {after_shop_type_filter} ä¸ªå•†å“")
        
        # æ¸…æ´—å¹¶å‡†å¤‡å…¥åº“æ•°æ®
        keywords_to_insert = []
        for product in filtered_products:
            title = product.get('title', '')
            keyword = self.clean_title_as_keyword(title)
            
            if not keyword:
                continue
            
            keyword_data = {
                'keyword': keyword,
                'project_id': project_id,
                'source': 'taobao',
                'status': 'pending',
                'taobao_sales': product.get('sales'),
                'taobao_price': product.get('price'),
                'origin_url': product.get('detail_url'),
                'taobao_shop_name': product.get('shop_name'),
                'taobao_shop_type': product.get('shop_type'),
            }
            keywords_to_insert.append(keyword_data)
        
        # æ‰¹é‡æ’å…¥æ•°æ®åº“
        inserted = 0
        if keywords_to_insert:
            try:
                # åˆ†æ‰¹æ’å…¥ï¼ˆæ¯æ¬¡æœ€å¤š100æ¡ï¼‰
                batch_size = 100
                for i in range(0, len(keywords_to_insert), batch_size):
                    batch = keywords_to_insert[i:i + batch_size]
                    result = self.supabase.table('keywords').insert(batch).execute()
                    inserted += len(batch)
                    logger.info(f"å·²æ’å…¥ {inserted}/{len(keywords_to_insert)} æ¡å…³é”®è¯")
                
                logger.info(f"âœ… æˆåŠŸæ’å…¥ {inserted} æ¡å…³é”®è¯åˆ°æ•°æ®åº“")
            except Exception as e:
                logger.error(f"âŒ æ’å…¥æ•°æ®åº“å¤±è´¥: {str(e)}")
                raise
        
        return {
            'total_crawled': total_crawled,
            'after_sales_filter': after_sales_filter,
            'after_price_filter': after_price_filter,
            'after_keyword_filter': after_keyword_filter,
            'after_shop_type_filter': after_shop_type_filter,
            'inserted': inserted
        }


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='æ·˜å®å…³é”®è¯æŒ–æ˜å·¥å…·')
    parser.add_argument('--headless', action='store_true', help='æ— å¤´æ¨¡å¼è¿è¡Œï¼ˆç™»å½•æ—¶ä¸å»ºè®®ä½¿ç”¨ï¼‰')
    parser.add_argument('--auth-file', default='auth_taobao.json', help='è®¤è¯æ–‡ä»¶è·¯å¾„ (é»˜è®¤: auth_taobao.json)')
    
    # ç™»å½•ç›¸å…³å‚æ•°
    parser.add_argument('--setup-login', action='store_true', help='è®¾ç½®ç™»å½•ï¼ˆæ‰«ç ç™»å½•å¹¶ä¿å­˜Cookiesï¼‰')
    parser.add_argument('--check-login', action='store_true', help='æ£€æŸ¥ç™»å½•çŠ¶æ€ï¼ˆéªŒè¯Cookiesæ˜¯å¦æœ‰æ•ˆï¼‰')
    parser.add_argument('--non-interactive', action='store_true', help='éäº¤äº’æ¨¡å¼ï¼ˆè‡ªåŠ¨æ£€æµ‹ç™»å½•å®Œæˆï¼Œç”¨äº API è°ƒç”¨ï¼‰')
    
    # æŒ–æ˜ç›¸å…³å‚æ•°
    parser.add_argument('--mine', action='store_true', help='å¼€å§‹æŒ–æ˜å…³é”®è¯')
    parser.add_argument('--seed-words', type=str, help='ç§å­è¯åˆ—è¡¨ï¼Œç”¨é€—å·åˆ†éš”ï¼Œä¾‹å¦‚: "é‡ç”Ÿ,è‡ªåˆ¶"')
    parser.add_argument('--project-id', type=str, help='é¡¹ç›® IDï¼ˆå¿…éœ€ï¼Œç”¨äºå°†æ•°æ®å…³è”åˆ°é¡¹ç›®ï¼‰')
    parser.add_argument('--max-pages', type=int, default=5, help='æ¯ä¸ªç§å­è¯æœ€å¤šæŠ“å–é¡µæ•° (é»˜è®¤: 5)')
    parser.add_argument('--min-sales', type=int, default=50, help='æœ€å°é”€é‡è¿‡æ»¤ (é»˜è®¤: 50)')
    parser.add_argument('--max-sales', type=int, default=5000, help='æœ€å¤§é”€é‡è¿‡æ»¤ (é»˜è®¤: 5000)')
    
    # ç­›é€‰å‚æ•°
    parser.add_argument('--min-price', type=float, help='æœ€å°ä»·æ ¼è¿‡æ»¤ï¼ˆå¯é€‰ï¼‰')
    parser.add_argument('--max-price', type=float, help='æœ€å¤§ä»·æ ¼è¿‡æ»¤ï¼ˆå¯é€‰ï¼‰')
    parser.add_argument('--must-contain', type=str, help='å¿…é¡»åŒ…å«çš„å…³é”®è¯åˆ—è¡¨ï¼Œç”¨é€—å·åˆ†éš”ï¼ˆå¯é€‰ï¼‰')
    parser.add_argument('--must-not-contain', type=str, help='ä¸èƒ½åŒ…å«çš„å…³é”®è¯åˆ—è¡¨ï¼Œç”¨é€—å·åˆ†éš”ï¼ˆå¯é€‰ï¼‰')
    parser.add_argument('--shop-type', type=str, choices=['tmall', 'c_shop', 'all'], 
                       help='åº—é“ºç±»å‹è¿‡æ»¤: tmall(å¤©çŒ«), c_shop(Cåº—), all(ä¸é™ï¼Œé»˜è®¤)')
    
    # Supabase é…ç½®ï¼ˆå¯é€‰ï¼Œä¼˜å…ˆä½¿ç”¨ç¯å¢ƒå˜é‡ï¼‰
    parser.add_argument('--supabase-url', type=str, help='Supabase é¡¹ç›® URL')
    parser.add_argument('--supabase-key', type=str, help='Supabase API Key')
    
    args = parser.parse_args()
    
    # åˆ›å»ºæŒ–æ˜å™¨å®ä¾‹
    miner = TaobaoMiner(
        headless=args.headless,
        auth_file=args.auth_file,
        supabase_url=args.supabase_url,
        supabase_key=args.supabase_key
    )
    
    # æ£€æŸ¥ç™»å½•çŠ¶æ€
    if args.check_login:
        logger.info("=" * 60)
        logger.info("æ£€æŸ¥ç™»å½•çŠ¶æ€...")
        logger.info("=" * 60)
        
        with sync_playwright() as p:
            browser, context, page = miner.create_browser_context(p)
            try:
                # åŠ è½½ Cookies
                if not miner.load_cookies(page):
                    logger.info("æœªæ‰¾åˆ°è®¤è¯æ–‡ä»¶æˆ–åŠ è½½å¤±è´¥")
                    import sys
                    sys.stderr.write("LOGIN_STATUS:false\n")
                    sys.stderr.flush()
                    return
                
                # æ£€æŸ¥ç™»å½•çŠ¶æ€
                is_logged_in = miner.is_logged_in(page)
                
                if is_logged_in:
                    logger.info("âœ… å·²ç™»å½•ï¼ŒCookies æœ‰æ•ˆ")
                else:
                    logger.warning("âŒ æœªç™»å½•æˆ– Cookies å·²å¤±æ•ˆ")
                
                # è¾“å‡ºçŠ¶æ€æ ‡å¿—ï¼ˆç”¨äº API è§£æï¼‰
                # ä½¿ç”¨ sys.stderr é¿å…ä¸æ—¥å¿—æ··æ·†
                import sys
                sys.stderr.write(f"LOGIN_STATUS:{'true' if is_logged_in else 'false'}\n")
                sys.stderr.flush()
                    
            except Exception as e:
                logger.error(f"æ£€æŸ¥ç™»å½•çŠ¶æ€æ—¶å‡ºé”™: {str(e)}")
                import sys
                sys.stderr.write("LOGIN_STATUS:false\n")
                sys.stderr.flush()
            finally:
                browser.close()
        
        return
    
    # æ‰§è¡Œç™»å½•è®¾ç½®
    if args.setup_login:
        logger.info("=" * 60)
        logger.info("æ·˜å®å…³é”®è¯æŒ–æ˜å·¥å…· - ç™»å½•è®¾ç½®")
        logger.info("=" * 60)
        
        success = miner.setup_login(interactive=not args.non_interactive)
        
        if success:
            logger.info("=" * 60)
            logger.info("âœ… ç™»å½•è®¾ç½®å®Œæˆï¼")
            logger.info("=" * 60)
            logger.info("æ¥ä¸‹æ¥å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å¼€å§‹æŒ–æ˜ï¼š")
            logger.info("  python scripts/taobao_miner.py --mine --seed-words 'é‡ç”Ÿ,è‡ªåˆ¶'")
            logger.info("=" * 60)
        else:
            logger.error("=" * 60)
            logger.error("âŒ ç™»å½•è®¾ç½®å¤±è´¥ï¼Œè¯·é‡è¯•")
            logger.error("=" * 60)
    
    # æ‰§è¡ŒæŒ–æ˜
    elif args.mine:
        if not args.seed_words:
            logger.error("âŒ è¯·æŒ‡å®šç§å­è¯: --seed-words 'é‡ç”Ÿ,è‡ªåˆ¶'")
            return
        
        # è§£æç§å­è¯åˆ—è¡¨
        seed_words = [w.strip() for w in args.seed_words.split(',') if w.strip()]
        if not seed_words:
            logger.error("âŒ ç§å­è¯åˆ—è¡¨ä¸ºç©º")
            return
        
        # å¦‚æœæŒ‡å®šäº†é¡¹ç›® IDï¼Œæ‰§è¡Œå®Œæ•´æµç¨‹ï¼ˆæŠ“å–+è¿‡æ»¤+å…¥åº“ï¼‰
        if args.project_id:
            # è§£æå…³é”®è¯ç­›é€‰å‚æ•°
            must_contain = None
            if args.must_contain:
                must_contain = [w.strip() for w in args.must_contain.split(',') if w.strip()]
            
            must_not_contain = None
            if args.must_not_contain:
                must_not_contain = [w.strip() for w in args.must_not_contain.split(',') if w.strip()]
            
            result = miner.mine_and_save(
                seed_words=seed_words,
                project_id=args.project_id,
                max_pages=args.max_pages,
                min_sales=args.min_sales,
                max_sales=args.max_sales,
                min_price=args.min_price,
                max_price=args.max_price,
                must_contain_keywords=must_contain,
                must_not_contain_keywords=must_not_contain,
                shop_type=args.shop_type if args.shop_type != 'all' else None
            )
            
            logger.info("=" * 60)
            logger.info("âœ… æŒ–æ˜å’Œå…¥åº“å®Œæˆï¼")
            logger.info(f"   æŠ“å–: {result['total_crawled']} ä¸ªå•†å“")
            logger.info(f"   é”€é‡è¿‡æ»¤å: {result['after_sales_filter']} ä¸ªå•†å“")
            if args.min_price or args.max_price:
                logger.info(f"   ä»·æ ¼è¿‡æ»¤å: {result['after_price_filter']} ä¸ªå•†å“")
            if must_contain or must_not_contain:
                logger.info(f"   å…³é”®è¯è¿‡æ»¤å: {result['after_keyword_filter']} ä¸ªå•†å“")
            if args.shop_type and args.shop_type != 'all':
                logger.info(f"   åº—é“ºç±»å‹è¿‡æ»¤å: {result['after_shop_type_filter']} ä¸ªå•†å“")
            logger.info(f"   æœ€ç»ˆå…¥åº“: {result['inserted']} æ¡å…³é”®è¯")
            logger.info("=" * 60)
            logger.info("ğŸ’¡ æç¤º: å¯ä»¥åˆ° Dashboard æŸ¥çœ‹æ–°å¯¼å…¥çš„æ•°æ® (source=taobao)")
        else:
            # åªæŠ“å–ä¸å…¥åº“ï¼ˆç”¨äºæµ‹è¯•ï¼‰
            logger.warning("âš ï¸ æœªæŒ‡å®šé¡¹ç›® IDï¼ŒåªæŠ“å–ä¸å…¥åº“ï¼ˆç”¨äºæµ‹è¯•ï¼‰")
            logger.info("ğŸ’¡ æç¤º: ä½¿ç”¨ --project-id <é¡¹ç›®ID> å¯ä»¥å°†æ•°æ®ä¿å­˜åˆ°æ•°æ®åº“")
            
            products = miner.mine_keywords(
                seed_words=seed_words,
                max_pages=args.max_pages,
                min_sales=args.min_sales,
                max_sales=args.max_sales
            )
            
            # æ‰“å°ç»“æœæ‘˜è¦
            logger.info("=" * 60)
            logger.info("æŠ“å–ç»“æœæ‘˜è¦:")
            logger.info("=" * 60)
            
            for i, product in enumerate(products[:10], 1):  # åªæ˜¾ç¤ºå‰10ä¸ª
                logger.info(f"{i}. {product.get('title', 'N/A')[:50]}...")
                logger.info(f"   ä»·æ ¼: {product.get('price', 'N/A')} | é”€é‡: {product.get('sales', 'N/A')} | åº—é“º: {product.get('shop_name', 'N/A')}")
            
            if len(products) > 10:
                logger.info(f"... è¿˜æœ‰ {len(products) - 10} ä¸ªå•†å“")
            
            logger.info("=" * 60)
            logger.info(f"æ€»è®¡: {len(products)} ä¸ªå•†å“")
            logger.info("=" * 60)
        
    else:
        # é»˜è®¤æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯
        parser.print_help()
        logger.info("")
        logger.info("ä½¿ç”¨ç¤ºä¾‹:")
        logger.info("  1. é¦–æ¬¡ç™»å½•: python scripts/taobao_miner.py --setup-login")
        logger.info("  2. å¼€å§‹æŒ–æ˜ï¼ˆå«å…¥åº“ï¼‰: python scripts/taobao_miner.py --mine --seed-words 'é‡ç”Ÿ,è‡ªåˆ¶' --project-id <é¡¹ç›®ID>")
        logger.info("  3. åªæµ‹è¯•æŠ“å–ï¼ˆä¸å…¥åº“ï¼‰: python scripts/taobao_miner.py --mine --seed-words 'é‡ç”Ÿ,è‡ªåˆ¶'")


if __name__ == "__main__":
    main()

