# NicheMiner 项目说明文档

## 📋 项目概述

**NicheMiner**（利基挖掘器）是一个专门用于关键词选品的智能工具系统，主要面向电商和SEO从业人员。系统能够从 5118 平台导出的 CSV 文件中导入大量关键词数据，通过智能分词和人工筛选相结合的方式，快速识别和筛选出具有商业价值的"蓝海关键词"，帮助用户发现潜在的商业机会。

**版本**: v0.2  
**项目类型**: Web 应用程序  
**开发框架**: Next.js 16

---

## 🎯 核心功能

### 1. 数据导入（Step 1: 导入）
- **智能 CSV 解析**: 自动识别 5118 平台的 CSV 文件格式，支持表头偏移定位
- **批量数据处理**: 支持一次性导入 10 万行以上数据
- **编码兼容**: 自动处理 GB18030 中文编码
- **进度显示**: 实时显示导入进度和状态

### 2. 智能清洗（Step 2: 智能清洗）
- **中文分词分析**: 使用 segmentit 库对关键词进行分词处理
- **特征词提取**: 自动提取高频特征词，供用户快速判断
- **级联操作**: 支持按特征词批量保留或删除相关关键词
- **智能去重**: 已处理的特征词不会重复出现
- **自动清洗规则**:
  - 流量过滤（低流量关键词）
  - 数字过滤（纯数字关键词）
  - 长度过滤（过长关键词）
- **持久化缓存**: 使用 localStorage 保存已处理的特征词，防止刷新丢失

### 3. 选品看板（Step 3: 选品看板）
- **蓝海评分算法**: 自动计算 `蓝海分 = 搜索量 / (竞争度 + 1)`
- **Top 100 榜单**: 展示性价比最高的 100 个关键词
- **数据可视化**: 使用散点图展示关键词的流量与竞争度分布
- **批量导出**: 支持导出为 CSV 文件（Excel 兼容），包含自定义字段映射
- **实时统计**: 显示有效关键词总数、已剔除数量等统计信息

---

## 🛠 技术栈

### 前端框架
- **Next.js 16.0.7**: React 全栈框架，支持服务端渲染和静态生成
- **React 19.2.0**: UI 框架
- **TypeScript 5**: 类型安全的 JavaScript

### UI 与样式
- **Tailwind CSS 4**: 原子化 CSS 框架
- **Lucide React**: 图标库
- **Geist Font**: Vercel 字体

### 数据可视化
- **Recharts 3.5.1**: React 图表库（散点图、柱状图）

### 数据处理
- **PapaParse 5.5.3**: CSV 文件解析和生成
- **Segmentit 2.0.3**: 中文分词库

### 后端服务
- **Supabase**: BaaS（后端即服务）平台
  - PostgreSQL 数据库
  - 实时数据同步
  - RPC 函数（存储过程）

### 工具库
- **clsx**: className 工具
- **tailwind-merge**: Tailwind 类名合并

---

## 📁 项目结构

```
niche-miner/
├── docs/                    # 文档文件夹
│   └── 项目说明.md         # 本文档
├── public/                  # 静态资源
│   ├── file.svg
│   ├── globe.svg
│   ├── next.svg
│   ├── vercel.svg
│   └── window.svg
├── src/
│   ├── app/                 # Next.js App Router
│   │   ├── components/      # React 组件
│   │   │   ├── StepDashboard.tsx    # 选品看板组件
│   │   │   ├── StepImport.tsx       # 数据导入组件
│   │   │   └── StepRules.tsx        # 智能清洗组件
│   │   ├── favicon.ico
│   │   ├── globals.css      # 全局样式
│   │   ├── layout.tsx       # 根布局
│   │   └── page.tsx         # 主页面（步骤管理）
│   ├── lib/                 # 工具库
│   │   └── supabaseClient.ts # Supabase 客户端配置
│   └── types.d.ts           # TypeScript 类型定义
├── .gitignore
├── eslint.config.mjs        # ESLint 配置
├── next.config.ts           # Next.js 配置
├── package.json             # 项目依赖
├── postcss.config.mjs       # PostCSS 配置
├── README.md                # 项目 README
└── tsconfig.json            # TypeScript 配置
```

---

## 🔧 核心模块说明

### 1. StepImport（数据导入模块）

**位置**: `src/app/components/StepImport.tsx`

**主要功能**:
- 文件上传处理（CSV 格式）
- 智能定位表头行（自动识别"关键词"列）
- 数据映射和清洗（提取 PC 流量、移动流量、竞争度等）
- 批量插入数据库（每批 500 条）

**关键特性**:
- 支持 5118 平台 CSV 格式的表头偏移
- 处理特殊值（"-"、"未收录"等）转为 0
- 自动计算总搜索量（PC + 移动）
- 进度条实时反馈

**数据映射**:
```typescript
{
  project_id: string,        // 项目 ID
  term: string,              // 关键词
  pc_volume: number,         // PC 日检索量
  mobile_volume: number,     // 移动日检索量
  search_volume: number,     // 总搜索量（PC + 移动）
  competition: number,       // 竞争激烈程度
  status: 'pending'          // 初始状态
}
```

---

### 2. StepRules（智能清洗模块）

**位置**: `src/app/components/StepRules.tsx`

**主要功能**:
- 分词分析（使用 segmentit 对关键词进行中文分词）
- 特征词提取（统计高频词根）
- 级联操作（保留/删除包含特定特征词的所有关键词）
- 自动清洗规则执行

**清洗规则**:
1. **流量过滤** (`clean_rule_volume`): 过滤低流量关键词
2. **数字过滤** (`clean_rule_digits`): 过滤纯数字关键词
3. **长度过滤** (`clean_rule_long`): 过滤过长关键词

**交互流程**:
1. 随机采样 5000 条待处理关键词
2. 分词提取特征词（Top 100）
3. 用户点击"是产品"或"垃圾"按钮
4. 系统级联更新所有相关关键词的状态
5. 已处理的特征词加入黑名单，不再显示

**状态管理**:
- `pending`: 待分类
- `valid`: 已确认（金矿关键词）
- `trash`: 已剔除（垃圾关键词）

---

### 3. StepDashboard（选品看板模块）

**位置**: `src/app/components/StepDashboard.tsx`

**主要功能**:
- 数据统计展示（有效关键词总数）
- Top 100 蓝海关键词榜单
- 散点图可视化（流量 vs 竞争度）
- CSV 批量导出

**蓝海评分算法**:
```typescript
blue_ocean_score = Math.round(search_volume / (competition + 1))
```
- **搜索量越高**，分数越高
- **竞争度越低**，分数越高
- 分数越高，代表性价比越高（蓝海潜力越大）

**导出功能**:
- 批量导出（每批 1000 条）
- 字段映射（中文列名）:
  - `排名`: 自动生成的排名
  - `关键词`: 关键词文本
  - `日搜索量`: 总搜索量
  - `竞争度`: 竞争激烈程度
  - `蓝海分`: 计算得出的蓝海评分
  - `PC流量`: PC 端流量
  - `移动流量`: 移动端流量
- 支持 Excel 打开（UTF-8 BOM）

---

## 🗄️ 数据库设计

基于代码推断，Supabase 数据库包含以下表结构：

### projects（项目表）
```sql
{
  id: string (UUID, Primary Key),
  name: string,
  created_at: timestamp
}
```

### keywords（关键词表）
```sql
{
  id: string (UUID, Primary Key),
  project_id: string (Foreign Key -> projects.id),
  term: string,              // 关键词文本
  pc_volume: number,         // PC 日检索量
  mobile_volume: number,     // 移动日检索量
  search_volume: number,     // 总搜索量
  competition: number,       // 竞争激烈程度
  status: enum('pending' | 'valid' | 'trash'),
  created_at: timestamp,
  updated_at: timestamp
}
```

### Supabase RPC 函数（存储过程）

1. **get_project_stats**: 获取项目统计信息
   - 参数: `p_id` (项目 ID)
   - 返回: `{ valid_count, trash_count, pending_count }`

2. **set_valid_by_token**: 按特征词批量设置为有效
   - 参数: `p_id`, `token` (特征词)
   - 功能: 将所有包含该特征词的关键词状态设为 `valid`

3. **clean_by_token**: 按特征词批量删除
   - 参数: `p_id`, `token` (特征词)
   - 功能: 将所有包含该特征词的关键词状态设为 `trash`

4. **clean_rule_volume**: 按流量规则清洗
   - 参数: `p_id`
   - 功能: 自动过滤低流量关键词

5. **clean_rule_digits**: 按数字规则清洗
   - 参数: `p_id`
   - 功能: 自动过滤纯数字关键词

6. **clean_rule_long**: 按长度规则清洗
   - 参数: `p_id`
   - 功能: 自动过滤过长关键词

7. **reset_project_status**: 重置项目状态
   - 参数: `p_id`
   - 功能: 将所有关键词状态重置为 `pending`

---

## 🔄 工作流程

### 完整流程

```
┌─────────────────┐
│  1. 导入数据     │
│  上传 CSV 文件   │
│  解析并入库      │
└────────┬────────┘
         │
         ▼
┌─────────────────┐
│  2. 智能清洗     │
│  分词提取特征词  │
│  人工筛选判断    │
│  级联更新状态    │
└────────┬────────┘
         │
         ▼
┌─────────────────┐
│  3. 选品看板     │
│  查看 Top 100    │
│  可视化分析      │
│  导出 CSV        │
└─────────────────┘
```

### 详细步骤

#### 步骤 1: 导入数据
1. 用户选择 5118 平台的 CSV 文件
2. 系统自动识别表头位置（查找"关键词"列）
3. 解析 CSV 数据，提取关键字段
4. 创建项目记录
5. 批量插入关键词数据（状态: `pending`）
6. 显示导入进度，完成后进入步骤 2

#### 步骤 2: 智能清洗
1. 系统随机采样待处理关键词（5000 条）
2. 对关键词进行中文分词
3. 统计高频特征词（Top 100）
4. 用户点击"是产品"或"垃圾"按钮
5. 系统级联更新所有包含该特征词的关键词状态
6. 已处理的特征词加入黑名单（localStorage）
7. 重复步骤 1-6，直到用户满意或点击"查看结果"

**可选操作**:
- **自动粗清洗**: 执行预设的清洗规则（流量、数字、长度）
- **重置项目**: 清空所有进度，重新开始

#### 步骤 3: 选品看板
1. 系统加载有效关键词数据（`status != 'trash'`）
2. 计算蓝海评分，排序取 Top 100
3. 生成散点图数据（Top 300 样本）
4. 展示统计信息和可视化图表
5. 用户可导出筛选后的关键词为 CSV 文件

---

## 🎨 UI/UX 特性

### 设计风格
- **现代简约**: 使用 Tailwind CSS 构建的现代化界面
- **渐变色**: 品牌色使用蓝色到靛蓝色的渐变
- **卡片式布局**: 内容以卡片形式组织，层次清晰

### 交互体验
- **步骤导航**: 顶部显示当前步骤，支持返回上一步
- **实时反馈**: 所有操作都有加载状态和进度提示
- **响应式设计**: 适配不同屏幕尺寸
- **动画效果**: 使用 CSS 动画增强视觉体验

### 状态指示
- **颜色编码**:
  - 🟢 绿色: 已确认（valid）
  - 🔴 红色: 已剔除（trash）
  - ⚪ 灰色: 待分类（pending）

---

## 🔐 环境配置

### 必需的环境变量

在项目根目录创建 `.env.local` 文件：

```env
NEXT_PUBLIC_SUPABASE_URL=your_supabase_project_url
NEXT_PUBLIC_SUPABASE_ANON_KEY=your_supabase_anon_key
```

### 安装依赖

```bash
npm install
```

### 运行开发服务器

```bash
npm run dev
```

访问: http://localhost:3000

### 构建生产版本

```bash
npm run build
npm start
```

---

## 📊 性能优化

### 数据处理优化
- **批量操作**: 数据库操作采用批量插入（500-1000 条/批）
- **随机采样**: 清洗阶段使用随机采样，避免总是处理相同数据
- **分页加载**: 导出时使用分页拉取，避免一次性加载大量数据

### 前端优化
- **按需加载**: 使用 Next.js 的代码分割
- **状态持久化**: 使用 localStorage 保存已处理特征词
- **懒加载**: 图表和大型组件按需加载

---

## 🚀 未来改进方向

### 功能增强
- [ ] 支持多项目管理（项目列表）
- [ ] 关键词搜索和筛选
- [ ] 自定义清洗规则配置
- [ ] 更多可视化图表（趋势分析、词云等）
- [ ] 关键词分类标签系统
- [ ] 导出格式扩展（JSON、Excel 等）

### 技术优化
- [ ] 添加单元测试和集成测试
- [ ] 性能监控和错误追踪
- [ ] 国际化支持（i18n）
- [ ] PWA 支持（离线使用）
- [ ] 数据备份和恢复功能

### 用户体验
- [ ] 快捷键支持
- [ ] 批量操作界面优化
- [ ] 操作历史记录
- [ ] 自定义主题

---

## 📝 注意事项

1. **数据源格式**: 目前仅支持 5118 平台的 CSV 导出格式
2. **编码问题**: CSV 文件需使用 GB18030 编码（代码中已处理）
3. **浏览器兼容**: 建议使用现代浏览器（Chrome、Edge、Firefox 最新版）
4. **数据量限制**: 虽然支持大量数据，但建议单次导入不超过 20 万条
5. **Supabase 配置**: 需要正确配置 Supabase 数据库表和 RPC 函数

---

## 📞 技术支持

如有问题或建议，请查看项目 README 或联系开发团队。

---

**文档版本**: 1.0  
**最后更新**: 2024-12-24  
**维护者**: NicheMiner 开发团队




